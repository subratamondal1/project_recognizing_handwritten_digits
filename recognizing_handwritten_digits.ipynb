{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMrhudARws4ssipLEConEiI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/subratamondal1/project_recognizing_handwritten_digits/blob/main/recognizing_handwritten_digits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìö Project -- Recognizing Handwritten Digits\n",
        "\n",
        "## Introduction\n",
        "We will build a Neural Network that can recognize handwritten numbers. To achieve this goal, we use **MNIST**, a database of handwritten digits made up of a training set of **60,000** examples, and a test set of 10,000 examples. The training examples are annotated by humans with the correct answer. For instance, if the handwritten digit is the number ‚Äú3,‚Äù then 3 is simply the label associated with that example.\n",
        "* **`Supervised Learning ---`** a type of machine learning that uses labeled data to train a model that can classify data or predict outcomes.\n",
        "* Each MNIST image is in **grayscale** and consists of **28 x 28** pixels."
      ],
      "metadata": {
        "id": "dQpH0QjmIP8w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining a Simple Neural Network\n",
        "We start with a very simple neural network and then progressively improve it.\n",
        "\n",
        "### Import Libraries"
      ],
      "metadata": {
        "id": "3lUKb5rIJOpG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9AR2jtGtIH4V"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Dataset"
      ],
      "metadata": {
        "id": "gEbHo6RYfq20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = keras.datasets.mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "print(f\"Training Data: {X_train.shape}\")\n",
        "print(f\"Testing Data: {X_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpsMwIYYfqGQ",
        "outputId": "bfa00f37-6d1a-478e-8c61-1964f28e441f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Training Data: (60000, 28, 28)\n",
            "Testing Data: (10000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_MEWB9hPnFbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Display Data"
      ],
      "metadata": {
        "id": "teQmcoAZnHTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(2, 2, sharey=True, sharex=True)\n",
        "axs[0,0].imshow(X_train[44])\n",
        "axs[0,0].set_title(y_train[44])\n",
        "\n",
        "axs[0,1].imshow(X_train[55])\n",
        "axs[0,1].set_title(y_train[55])\n",
        "\n",
        "axs[1,0].imshow(X_train[66])\n",
        "axs[1,0].set_title(y_train[66])\n",
        "\n",
        "axs[1,1].imshow(X_train[77])\n",
        "axs[1,1].set_title(y_train[77])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "gOv79wlYiMtd",
        "outputId": "7e710c52-be6a-4512-ce0c-0b0b63f91f60"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, '1')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Network and Train\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 128\n",
        "VERBOSE = 1\n",
        "NB_CLASSES = 10 # number of outputs = number of digits\n",
        "N_HIDDEN = 128\n",
        "VALIDATION_SPLIT = 0.2 # how much TRAIN is reserved for VALIDATION\n",
        "\n",
        "# X_train is 60000 rows of 28x28 values; we  --> reshape it to 60000 x 784.\n",
        "RESHAPED = 784 # 28x28 = 784\n",
        "# the reshaped DATA will have a shape of (60000, 784), where each row is a vector representation of an image.\n",
        "X_train = X_train.reshape(X_train.shape[0], RESHAPED)\n",
        "X_test = X_test.reshape(X_test.shape[0], RESHAPED)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# Normalize inputs in range [0,1]\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "print(X_train.shape[0], \"Train Samples\")\n",
        "print(X_test.shape[0], \"Test Samples\")\n",
        "\n",
        "# One Hot representation of the data\n",
        "y_train = keras.utils.to_categorical(y_train, NB_CLASSES)\n",
        "y_test = keras.utils.to_categorical(y_test, NB_CLASSES)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIcgG5cKKNtg",
        "outputId": "84ef6710-9af2-4ea3-faa1-c40058a19ecf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000 Train Samples\n",
            "10000 Test Samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model.\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(\n",
        "    keras.layers.Dense(NB_CLASSES,\n",
        "    input_shape=(RESHAPED,),\n",
        "    name='dense_layer',\n",
        "    activation='softmax'))"
      ],
      "metadata": {
        "id": "rai63AK6dsAb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling the model.\n",
        "model.compile(optimizer='SGD',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "it2L84v0ePt9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model.\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE, epochs=EPOCHS,\n",
        "          verbose=VERBOSE, validation_split=VALIDATION_SPLIT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7mQ3-S8nvk1",
        "outputId": "6c007233-c8e0-47f4-bdf3-906e552e8cf0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.3741 - accuracy: 0.6682 - val_loss: 0.8897 - val_accuracy: 0.8328\n",
            "Epoch 2/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.7905 - accuracy: 0.8301 - val_loss: 0.6524 - val_accuracy: 0.8622\n",
            "Epoch 3/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.6407 - accuracy: 0.8518 - val_loss: 0.5573 - val_accuracy: 0.8747\n",
            "Epoch 4/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5685 - accuracy: 0.8624 - val_loss: 0.5048 - val_accuracy: 0.8793\n",
            "Epoch 5/100\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5247 - accuracy: 0.8690 - val_loss: 0.4712 - val_accuracy: 0.8845\n",
            "Epoch 6/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4946 - accuracy: 0.8738 - val_loss: 0.4472 - val_accuracy: 0.8888\n",
            "Epoch 7/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4725 - accuracy: 0.8778 - val_loss: 0.4292 - val_accuracy: 0.8919\n",
            "Epoch 8/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4553 - accuracy: 0.8809 - val_loss: 0.4152 - val_accuracy: 0.8954\n",
            "Epoch 9/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4414 - accuracy: 0.8838 - val_loss: 0.4038 - val_accuracy: 0.8972\n",
            "Epoch 10/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4299 - accuracy: 0.8863 - val_loss: 0.3944 - val_accuracy: 0.8997\n",
            "Epoch 11/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4203 - accuracy: 0.8882 - val_loss: 0.3865 - val_accuracy: 0.9010\n",
            "Epoch 12/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4119 - accuracy: 0.8892 - val_loss: 0.3797 - val_accuracy: 0.9020\n",
            "Epoch 13/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4046 - accuracy: 0.8909 - val_loss: 0.3737 - val_accuracy: 0.9032\n",
            "Epoch 14/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3982 - accuracy: 0.8919 - val_loss: 0.3684 - val_accuracy: 0.9039\n",
            "Epoch 15/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3925 - accuracy: 0.8932 - val_loss: 0.3637 - val_accuracy: 0.9044\n",
            "Epoch 16/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3873 - accuracy: 0.8941 - val_loss: 0.3596 - val_accuracy: 0.9051\n",
            "Epoch 17/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3827 - accuracy: 0.8955 - val_loss: 0.3557 - val_accuracy: 0.9067\n",
            "Epoch 18/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3785 - accuracy: 0.8963 - val_loss: 0.3523 - val_accuracy: 0.9067\n",
            "Epoch 19/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3746 - accuracy: 0.8974 - val_loss: 0.3490 - val_accuracy: 0.9080\n",
            "Epoch 20/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3710 - accuracy: 0.8983 - val_loss: 0.3462 - val_accuracy: 0.9078\n",
            "Epoch 21/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3678 - accuracy: 0.8992 - val_loss: 0.3436 - val_accuracy: 0.9093\n",
            "Epoch 22/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3647 - accuracy: 0.8995 - val_loss: 0.3410 - val_accuracy: 0.9097\n",
            "Epoch 23/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3618 - accuracy: 0.9003 - val_loss: 0.3386 - val_accuracy: 0.9098\n",
            "Epoch 24/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3591 - accuracy: 0.9008 - val_loss: 0.3365 - val_accuracy: 0.9106\n",
            "Epoch 25/100\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3566 - accuracy: 0.9016 - val_loss: 0.3346 - val_accuracy: 0.9111\n",
            "Epoch 26/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3542 - accuracy: 0.9020 - val_loss: 0.3326 - val_accuracy: 0.9111\n",
            "Epoch 27/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3520 - accuracy: 0.9026 - val_loss: 0.3309 - val_accuracy: 0.9120\n",
            "Epoch 28/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3499 - accuracy: 0.9031 - val_loss: 0.3291 - val_accuracy: 0.9119\n",
            "Epoch 29/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3479 - accuracy: 0.9034 - val_loss: 0.3276 - val_accuracy: 0.9119\n",
            "Epoch 30/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3460 - accuracy: 0.9038 - val_loss: 0.3261 - val_accuracy: 0.9122\n",
            "Epoch 31/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3442 - accuracy: 0.9044 - val_loss: 0.3245 - val_accuracy: 0.9129\n",
            "Epoch 32/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3425 - accuracy: 0.9046 - val_loss: 0.3232 - val_accuracy: 0.9128\n",
            "Epoch 33/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3408 - accuracy: 0.9052 - val_loss: 0.3219 - val_accuracy: 0.9128\n",
            "Epoch 34/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3393 - accuracy: 0.9057 - val_loss: 0.3206 - val_accuracy: 0.9131\n",
            "Epoch 35/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3378 - accuracy: 0.9060 - val_loss: 0.3194 - val_accuracy: 0.9128\n",
            "Epoch 36/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3363 - accuracy: 0.9064 - val_loss: 0.3183 - val_accuracy: 0.9128\n",
            "Epoch 37/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3349 - accuracy: 0.9065 - val_loss: 0.3173 - val_accuracy: 0.9130\n",
            "Epoch 38/100\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3336 - accuracy: 0.9069 - val_loss: 0.3163 - val_accuracy: 0.9136\n",
            "Epoch 39/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3323 - accuracy: 0.9075 - val_loss: 0.3151 - val_accuracy: 0.9135\n",
            "Epoch 40/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3311 - accuracy: 0.9078 - val_loss: 0.3143 - val_accuracy: 0.9139\n",
            "Epoch 41/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3299 - accuracy: 0.9080 - val_loss: 0.3133 - val_accuracy: 0.9139\n",
            "Epoch 42/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3288 - accuracy: 0.9085 - val_loss: 0.3124 - val_accuracy: 0.9140\n",
            "Epoch 43/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3276 - accuracy: 0.9088 - val_loss: 0.3117 - val_accuracy: 0.9148\n",
            "Epoch 44/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3266 - accuracy: 0.9089 - val_loss: 0.3107 - val_accuracy: 0.9145\n",
            "Epoch 45/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3256 - accuracy: 0.9094 - val_loss: 0.3099 - val_accuracy: 0.9149\n",
            "Epoch 46/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3246 - accuracy: 0.9096 - val_loss: 0.3092 - val_accuracy: 0.9153\n",
            "Epoch 47/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3236 - accuracy: 0.9096 - val_loss: 0.3084 - val_accuracy: 0.9155\n",
            "Epoch 48/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3227 - accuracy: 0.9101 - val_loss: 0.3078 - val_accuracy: 0.9162\n",
            "Epoch 49/100\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3218 - accuracy: 0.9104 - val_loss: 0.3070 - val_accuracy: 0.9162\n",
            "Epoch 50/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3209 - accuracy: 0.9103 - val_loss: 0.3063 - val_accuracy: 0.9162\n",
            "Epoch 51/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3200 - accuracy: 0.9107 - val_loss: 0.3059 - val_accuracy: 0.9159\n",
            "Epoch 52/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3192 - accuracy: 0.9110 - val_loss: 0.3050 - val_accuracy: 0.9162\n",
            "Epoch 53/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3184 - accuracy: 0.9111 - val_loss: 0.3044 - val_accuracy: 0.9161\n",
            "Epoch 54/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3176 - accuracy: 0.9115 - val_loss: 0.3038 - val_accuracy: 0.9160\n",
            "Epoch 55/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3169 - accuracy: 0.9115 - val_loss: 0.3032 - val_accuracy: 0.9170\n",
            "Epoch 56/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3161 - accuracy: 0.9114 - val_loss: 0.3027 - val_accuracy: 0.9166\n",
            "Epoch 57/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3154 - accuracy: 0.9120 - val_loss: 0.3021 - val_accuracy: 0.9171\n",
            "Epoch 58/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3147 - accuracy: 0.9120 - val_loss: 0.3016 - val_accuracy: 0.9166\n",
            "Epoch 59/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3140 - accuracy: 0.9126 - val_loss: 0.3010 - val_accuracy: 0.9172\n",
            "Epoch 60/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3133 - accuracy: 0.9127 - val_loss: 0.3005 - val_accuracy: 0.9172\n",
            "Epoch 61/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3127 - accuracy: 0.9127 - val_loss: 0.3001 - val_accuracy: 0.9174\n",
            "Epoch 62/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3120 - accuracy: 0.9130 - val_loss: 0.2995 - val_accuracy: 0.9173\n",
            "Epoch 63/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3114 - accuracy: 0.9131 - val_loss: 0.2991 - val_accuracy: 0.9170\n",
            "Epoch 64/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.3108 - accuracy: 0.9136 - val_loss: 0.2987 - val_accuracy: 0.9175\n",
            "Epoch 65/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3102 - accuracy: 0.9135 - val_loss: 0.2982 - val_accuracy: 0.9175\n",
            "Epoch 66/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3096 - accuracy: 0.9140 - val_loss: 0.2978 - val_accuracy: 0.9177\n",
            "Epoch 67/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3090 - accuracy: 0.9141 - val_loss: 0.2973 - val_accuracy: 0.9181\n",
            "Epoch 68/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3085 - accuracy: 0.9143 - val_loss: 0.2969 - val_accuracy: 0.9183\n",
            "Epoch 69/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3079 - accuracy: 0.9146 - val_loss: 0.2966 - val_accuracy: 0.9182\n",
            "Epoch 70/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3074 - accuracy: 0.9147 - val_loss: 0.2961 - val_accuracy: 0.9183\n",
            "Epoch 71/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3069 - accuracy: 0.9146 - val_loss: 0.2956 - val_accuracy: 0.9183\n",
            "Epoch 72/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3064 - accuracy: 0.9147 - val_loss: 0.2953 - val_accuracy: 0.9193\n",
            "Epoch 73/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3058 - accuracy: 0.9151 - val_loss: 0.2950 - val_accuracy: 0.9184\n",
            "Epoch 74/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3054 - accuracy: 0.9153 - val_loss: 0.2946 - val_accuracy: 0.9189\n",
            "Epoch 75/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3049 - accuracy: 0.9153 - val_loss: 0.2943 - val_accuracy: 0.9187\n",
            "Epoch 76/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3044 - accuracy: 0.9154 - val_loss: 0.2940 - val_accuracy: 0.9190\n",
            "Epoch 77/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3039 - accuracy: 0.9156 - val_loss: 0.2936 - val_accuracy: 0.9184\n",
            "Epoch 78/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3035 - accuracy: 0.9154 - val_loss: 0.2932 - val_accuracy: 0.9193\n",
            "Epoch 79/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3030 - accuracy: 0.9159 - val_loss: 0.2929 - val_accuracy: 0.9193\n",
            "Epoch 80/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3026 - accuracy: 0.9158 - val_loss: 0.2926 - val_accuracy: 0.9193\n",
            "Epoch 81/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3021 - accuracy: 0.9157 - val_loss: 0.2923 - val_accuracy: 0.9192\n",
            "Epoch 82/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3017 - accuracy: 0.9160 - val_loss: 0.2920 - val_accuracy: 0.9195\n",
            "Epoch 83/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3013 - accuracy: 0.9161 - val_loss: 0.2917 - val_accuracy: 0.9195\n",
            "Epoch 84/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3009 - accuracy: 0.9163 - val_loss: 0.2914 - val_accuracy: 0.9194\n",
            "Epoch 85/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3005 - accuracy: 0.9166 - val_loss: 0.2910 - val_accuracy: 0.9197\n",
            "Epoch 86/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3001 - accuracy: 0.9163 - val_loss: 0.2907 - val_accuracy: 0.9195\n",
            "Epoch 87/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2997 - accuracy: 0.9163 - val_loss: 0.2905 - val_accuracy: 0.9197\n",
            "Epoch 88/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2993 - accuracy: 0.9165 - val_loss: 0.2902 - val_accuracy: 0.9194\n",
            "Epoch 89/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2989 - accuracy: 0.9166 - val_loss: 0.2899 - val_accuracy: 0.9193\n",
            "Epoch 90/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2986 - accuracy: 0.9167 - val_loss: 0.2897 - val_accuracy: 0.9201\n",
            "Epoch 91/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2982 - accuracy: 0.9168 - val_loss: 0.2894 - val_accuracy: 0.9196\n",
            "Epoch 92/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2978 - accuracy: 0.9175 - val_loss: 0.2893 - val_accuracy: 0.9199\n",
            "Epoch 93/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2975 - accuracy: 0.9170 - val_loss: 0.2889 - val_accuracy: 0.9199\n",
            "Epoch 94/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2971 - accuracy: 0.9171 - val_loss: 0.2887 - val_accuracy: 0.9197\n",
            "Epoch 95/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2968 - accuracy: 0.9173 - val_loss: 0.2884 - val_accuracy: 0.9200\n",
            "Epoch 96/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2964 - accuracy: 0.9174 - val_loss: 0.2882 - val_accuracy: 0.9197\n",
            "Epoch 97/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2961 - accuracy: 0.9175 - val_loss: 0.2880 - val_accuracy: 0.9202\n",
            "Epoch 98/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2958 - accuracy: 0.9174 - val_loss: 0.2878 - val_accuracy: 0.9204\n",
            "Epoch 99/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2955 - accuracy: 0.9176 - val_loss: 0.2875 - val_accuracy: 0.9202\n",
            "Epoch 100/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2951 - accuracy: 0.9178 - val_loss: 0.2873 - val_accuracy: 0.9207\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x797e91a7ba00>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate the model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdE7fFBJrDtc",
        "outputId": "a120a61a-e88a-426f-864c-4227451914d1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2879 - accuracy: 0.9208\n",
            "Test accuracy: 0.920799970626831\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Improving the simple net in TensorFlow with hidden layers"
      ],
      "metadata": {
        "id": "pbqPCiYnSwam"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Network and training.\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 128\n",
        "VERBOSE = 1\n",
        "NB_CLASSES = 10 # number of outputs = number of digits N_HIDDEN = 128\n",
        "VALIDATION_SPLIT = 0.2 # how much TRAIN is reserved for VALIDATION"
      ],
      "metadata": {
        "id": "4hz5fSn2sAMa"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading MNIST dataset.\n",
        "# Labels have one-hot representation.\n",
        "mnist = keras.datasets.mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# X_train is 60000 rows of 28x28 values; we reshape it to 60000 x 784.\n",
        "RESHAPED = 784\n",
        "\n",
        "X_train = X_train.reshape(60000, RESHAPED)\n",
        "X_test = X_test.reshape(10000, RESHAPED)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# Normalize inputs to be within in [0, 1].\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "\n",
        "# Labels have one-hot representation.\n",
        "y_train = tf.keras.utils.to_categorical(y_train, NB_CLASSES)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, NB_CLASSES)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kdNSgTsSJp0",
        "outputId": "c1241913-dcc5-4bba-d447-a07296789e21"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model.\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "model.add(\n",
        "    keras.layers.Dense(N_HIDDEN,\n",
        "    input_shape=(RESHAPED,),\n",
        "    name='dense_layer',\n",
        "    activation='relu'))\n",
        "\n",
        "model.add(\n",
        "    keras.layers.Dense(N_HIDDEN,\n",
        "    name='dense_layer_2',\n",
        "    activation='relu'))\n",
        "\n",
        "model.add(\n",
        "    keras.layers.Dense(NB_CLASSES,\n",
        "    name='dense_layer_3',\n",
        "    activation='softmax'))\n",
        "\n",
        "# Summary of the model.\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MbPC-eZT_N6",
        "outputId": "f5e2ce80-afa5-492f-d734-ebd811da2b1d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_layer (Dense)         (None, 128)               100480    \n",
            "                                                                 \n",
            " dense_layer_2 (Dense)       (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_layer_3 (Dense)       (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 118,282\n",
            "Trainable params: 118,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling the model.\n",
        "model.compile(\n",
        "    optimizer='SGD',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "TRdwozK2Uf-q"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model.\n",
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    batch_size=BATCH_SIZE, epochs=EPOCHS,\n",
        "    verbose=VERBOSE, validation_split=VALIDATION_SPLIT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7z4zDhjgVPA-",
        "outputId": "4eb0e1c7-db3b-404f-9ed9-28d6f9bf4556"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "375/375 [==============================] - 3s 6ms/step - loss: 1.6015 - accuracy: 0.5949 - val_loss: 0.8129 - val_accuracy: 0.8443\n",
            "Epoch 2/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6191 - accuracy: 0.8538 - val_loss: 0.4573 - val_accuracy: 0.8832\n",
            "Epoch 3/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.4395 - accuracy: 0.8829 - val_loss: 0.3740 - val_accuracy: 0.9001\n",
            "Epoch 4/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.3772 - accuracy: 0.8958 - val_loss: 0.3344 - val_accuracy: 0.9067\n",
            "Epoch 5/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.3428 - accuracy: 0.9035 - val_loss: 0.3105 - val_accuracy: 0.9123\n",
            "Epoch 6/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3192 - accuracy: 0.9100 - val_loss: 0.2928 - val_accuracy: 0.9162\n",
            "Epoch 7/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3010 - accuracy: 0.9147 - val_loss: 0.2794 - val_accuracy: 0.9208\n",
            "Epoch 8/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2862 - accuracy: 0.9194 - val_loss: 0.2673 - val_accuracy: 0.9244\n",
            "Epoch 9/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2737 - accuracy: 0.9231 - val_loss: 0.2561 - val_accuracy: 0.9279\n",
            "Epoch 10/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2624 - accuracy: 0.9260 - val_loss: 0.2471 - val_accuracy: 0.9298\n",
            "Epoch 11/100\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.2527 - accuracy: 0.9288 - val_loss: 0.2390 - val_accuracy: 0.9317\n",
            "Epoch 12/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2435 - accuracy: 0.9306 - val_loss: 0.2315 - val_accuracy: 0.9336\n",
            "Epoch 13/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2352 - accuracy: 0.9335 - val_loss: 0.2254 - val_accuracy: 0.9364\n",
            "Epoch 14/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2277 - accuracy: 0.9358 - val_loss: 0.2191 - val_accuracy: 0.9382\n",
            "Epoch 15/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2206 - accuracy: 0.9380 - val_loss: 0.2128 - val_accuracy: 0.9416\n",
            "Epoch 16/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.2138 - accuracy: 0.9396 - val_loss: 0.2089 - val_accuracy: 0.9410\n",
            "Epoch 17/100\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.2075 - accuracy: 0.9416 - val_loss: 0.2016 - val_accuracy: 0.9435\n",
            "Epoch 18/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2017 - accuracy: 0.9438 - val_loss: 0.1973 - val_accuracy: 0.9447\n",
            "Epoch 19/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1961 - accuracy: 0.9449 - val_loss: 0.1935 - val_accuracy: 0.9463\n",
            "Epoch 20/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1906 - accuracy: 0.9455 - val_loss: 0.1894 - val_accuracy: 0.9468\n",
            "Epoch 21/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1857 - accuracy: 0.9472 - val_loss: 0.1838 - val_accuracy: 0.9492\n",
            "Epoch 22/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1807 - accuracy: 0.9488 - val_loss: 0.1801 - val_accuracy: 0.9503\n",
            "Epoch 23/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.1763 - accuracy: 0.9498 - val_loss: 0.1765 - val_accuracy: 0.9508\n",
            "Epoch 24/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1720 - accuracy: 0.9515 - val_loss: 0.1729 - val_accuracy: 0.9522\n",
            "Epoch 25/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.1678 - accuracy: 0.9526 - val_loss: 0.1708 - val_accuracy: 0.9526\n",
            "Epoch 26/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1638 - accuracy: 0.9535 - val_loss: 0.1667 - val_accuracy: 0.9539\n",
            "Epoch 27/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1600 - accuracy: 0.9542 - val_loss: 0.1642 - val_accuracy: 0.9537\n",
            "Epoch 28/100\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.1564 - accuracy: 0.9555 - val_loss: 0.1606 - val_accuracy: 0.9550\n",
            "Epoch 29/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1527 - accuracy: 0.9565 - val_loss: 0.1587 - val_accuracy: 0.9557\n",
            "Epoch 30/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1496 - accuracy: 0.9574 - val_loss: 0.1551 - val_accuracy: 0.9570\n",
            "Epoch 31/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1464 - accuracy: 0.9584 - val_loss: 0.1535 - val_accuracy: 0.9580\n",
            "Epoch 32/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1433 - accuracy: 0.9594 - val_loss: 0.1514 - val_accuracy: 0.9579\n",
            "Epoch 33/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1401 - accuracy: 0.9603 - val_loss: 0.1486 - val_accuracy: 0.9583\n",
            "Epoch 34/100\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.1375 - accuracy: 0.9609 - val_loss: 0.1470 - val_accuracy: 0.9590\n",
            "Epoch 35/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1347 - accuracy: 0.9616 - val_loss: 0.1451 - val_accuracy: 0.9590\n",
            "Epoch 36/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1322 - accuracy: 0.9622 - val_loss: 0.1427 - val_accuracy: 0.9603\n",
            "Epoch 37/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1296 - accuracy: 0.9636 - val_loss: 0.1415 - val_accuracy: 0.9604\n",
            "Epoch 38/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1271 - accuracy: 0.9643 - val_loss: 0.1396 - val_accuracy: 0.9611\n",
            "Epoch 39/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1248 - accuracy: 0.9644 - val_loss: 0.1376 - val_accuracy: 0.9624\n",
            "Epoch 40/100\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.1225 - accuracy: 0.9652 - val_loss: 0.1357 - val_accuracy: 0.9624\n",
            "Epoch 41/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1203 - accuracy: 0.9660 - val_loss: 0.1342 - val_accuracy: 0.9633\n",
            "Epoch 42/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1181 - accuracy: 0.9665 - val_loss: 0.1335 - val_accuracy: 0.9636\n",
            "Epoch 43/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1159 - accuracy: 0.9673 - val_loss: 0.1320 - val_accuracy: 0.9632\n",
            "Epoch 44/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1139 - accuracy: 0.9682 - val_loss: 0.1305 - val_accuracy: 0.9635\n",
            "Epoch 45/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1121 - accuracy: 0.9686 - val_loss: 0.1294 - val_accuracy: 0.9636\n",
            "Epoch 46/100\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.1100 - accuracy: 0.9690 - val_loss: 0.1278 - val_accuracy: 0.9635\n",
            "Epoch 47/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1083 - accuracy: 0.9696 - val_loss: 0.1268 - val_accuracy: 0.9647\n",
            "Epoch 48/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1064 - accuracy: 0.9699 - val_loss: 0.1251 - val_accuracy: 0.9650\n",
            "Epoch 49/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1047 - accuracy: 0.9708 - val_loss: 0.1241 - val_accuracy: 0.9653\n",
            "Epoch 50/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1028 - accuracy: 0.9714 - val_loss: 0.1230 - val_accuracy: 0.9652\n",
            "Epoch 51/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1013 - accuracy: 0.9714 - val_loss: 0.1222 - val_accuracy: 0.9655\n",
            "Epoch 52/100\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0996 - accuracy: 0.9721 - val_loss: 0.1205 - val_accuracy: 0.9656\n",
            "Epoch 53/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0979 - accuracy: 0.9729 - val_loss: 0.1198 - val_accuracy: 0.9664\n",
            "Epoch 54/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0964 - accuracy: 0.9731 - val_loss: 0.1195 - val_accuracy: 0.9659\n",
            "Epoch 55/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0948 - accuracy: 0.9740 - val_loss: 0.1181 - val_accuracy: 0.9662\n",
            "Epoch 56/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0935 - accuracy: 0.9739 - val_loss: 0.1173 - val_accuracy: 0.9671\n",
            "Epoch 57/100\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.0920 - accuracy: 0.9746 - val_loss: 0.1161 - val_accuracy: 0.9672\n",
            "Epoch 58/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0903 - accuracy: 0.9748 - val_loss: 0.1154 - val_accuracy: 0.9677\n",
            "Epoch 59/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0892 - accuracy: 0.9751 - val_loss: 0.1143 - val_accuracy: 0.9677\n",
            "Epoch 60/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0878 - accuracy: 0.9754 - val_loss: 0.1137 - val_accuracy: 0.9676\n",
            "Epoch 61/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0865 - accuracy: 0.9758 - val_loss: 0.1136 - val_accuracy: 0.9682\n",
            "Epoch 62/100\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0851 - accuracy: 0.9763 - val_loss: 0.1124 - val_accuracy: 0.9685\n",
            "Epoch 63/100\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0839 - accuracy: 0.9767 - val_loss: 0.1114 - val_accuracy: 0.9679\n",
            "Epoch 64/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0826 - accuracy: 0.9773 - val_loss: 0.1105 - val_accuracy: 0.9685\n",
            "Epoch 65/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0815 - accuracy: 0.9772 - val_loss: 0.1095 - val_accuracy: 0.9691\n",
            "Epoch 66/100\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.0801 - accuracy: 0.9781 - val_loss: 0.1094 - val_accuracy: 0.9695\n",
            "Epoch 67/100\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0790 - accuracy: 0.9783 - val_loss: 0.1077 - val_accuracy: 0.9694\n",
            "Epoch 68/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0778 - accuracy: 0.9785 - val_loss: 0.1082 - val_accuracy: 0.9698\n",
            "Epoch 69/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0767 - accuracy: 0.9786 - val_loss: 0.1073 - val_accuracy: 0.9698\n",
            "Epoch 70/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0756 - accuracy: 0.9789 - val_loss: 0.1066 - val_accuracy: 0.9698\n",
            "Epoch 71/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0743 - accuracy: 0.9792 - val_loss: 0.1070 - val_accuracy: 0.9690\n",
            "Epoch 72/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0735 - accuracy: 0.9800 - val_loss: 0.1059 - val_accuracy: 0.9697\n",
            "Epoch 73/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0724 - accuracy: 0.9803 - val_loss: 0.1060 - val_accuracy: 0.9702\n",
            "Epoch 74/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0714 - accuracy: 0.9805 - val_loss: 0.1043 - val_accuracy: 0.9703\n",
            "Epoch 75/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0702 - accuracy: 0.9811 - val_loss: 0.1039 - val_accuracy: 0.9707\n",
            "Epoch 76/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0695 - accuracy: 0.9811 - val_loss: 0.1036 - val_accuracy: 0.9715\n",
            "Epoch 77/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0684 - accuracy: 0.9812 - val_loss: 0.1031 - val_accuracy: 0.9703\n",
            "Epoch 78/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0675 - accuracy: 0.9816 - val_loss: 0.1020 - val_accuracy: 0.9721\n",
            "Epoch 79/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0666 - accuracy: 0.9823 - val_loss: 0.1023 - val_accuracy: 0.9711\n",
            "Epoch 80/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0657 - accuracy: 0.9824 - val_loss: 0.1010 - val_accuracy: 0.9718\n",
            "Epoch 81/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0647 - accuracy: 0.9828 - val_loss: 0.1009 - val_accuracy: 0.9712\n",
            "Epoch 82/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0637 - accuracy: 0.9830 - val_loss: 0.1004 - val_accuracy: 0.9716\n",
            "Epoch 83/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0630 - accuracy: 0.9833 - val_loss: 0.1002 - val_accuracy: 0.9710\n",
            "Epoch 84/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0622 - accuracy: 0.9831 - val_loss: 0.0991 - val_accuracy: 0.9714\n",
            "Epoch 85/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0614 - accuracy: 0.9835 - val_loss: 0.0990 - val_accuracy: 0.9721\n",
            "Epoch 86/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0605 - accuracy: 0.9841 - val_loss: 0.0984 - val_accuracy: 0.9716\n",
            "Epoch 87/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0597 - accuracy: 0.9843 - val_loss: 0.0983 - val_accuracy: 0.9721\n",
            "Epoch 88/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0588 - accuracy: 0.9845 - val_loss: 0.0982 - val_accuracy: 0.9719\n",
            "Epoch 89/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0581 - accuracy: 0.9848 - val_loss: 0.0973 - val_accuracy: 0.9722\n",
            "Epoch 90/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0573 - accuracy: 0.9851 - val_loss: 0.0973 - val_accuracy: 0.9718\n",
            "Epoch 91/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0566 - accuracy: 0.9850 - val_loss: 0.0972 - val_accuracy: 0.9728\n",
            "Epoch 92/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0558 - accuracy: 0.9855 - val_loss: 0.0967 - val_accuracy: 0.9727\n",
            "Epoch 93/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0550 - accuracy: 0.9857 - val_loss: 0.0969 - val_accuracy: 0.9722\n",
            "Epoch 94/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0543 - accuracy: 0.9860 - val_loss: 0.0965 - val_accuracy: 0.9728\n",
            "Epoch 95/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0537 - accuracy: 0.9861 - val_loss: 0.0960 - val_accuracy: 0.9719\n",
            "Epoch 96/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0530 - accuracy: 0.9863 - val_loss: 0.0958 - val_accuracy: 0.9723\n",
            "Epoch 97/100\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0523 - accuracy: 0.9865 - val_loss: 0.0952 - val_accuracy: 0.9730\n",
            "Epoch 98/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0517 - accuracy: 0.9864 - val_loss: 0.0951 - val_accuracy: 0.9726\n",
            "Epoch 99/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0509 - accuracy: 0.9868 - val_loss: 0.0949 - val_accuracy: 0.9732\n",
            "Epoch 100/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0503 - accuracy: 0.9869 - val_loss: 0.0941 - val_accuracy: 0.9726\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x797e8277a470>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the model.\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edBtjnSwV0S7",
        "outputId": "020dcd31-36eb-4e61-d2f8-812c274afd32"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0876 - accuracy: 0.9744\n",
            "Test accuracy: 0.974399983882904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Further improving the simple net in TensorFlow with dropout\n",
        "**Dropout** is a technique to improve the performance of deep learning models *by reducing overfitting.* Overfitting is when a model learns the noise or specific patterns in the training data that do not generalize well to new or unseen data.\n",
        "\n",
        "* Dropout works by randomly dropping out some units or neurons in a layer during each training step, which prevents co-adaptation of features and forces the model to learn more robust representations.\n",
        "\n",
        "* Dropout also acts as a form of regularization, which means it reduces the complexity of the model and shrinks the weights towards zero.\n",
        "\n",
        "* Dropout can be applied to different types of layers in a neural network, such as fully-connected, convolutional, or recurrent layers. The rate of dropout is usually a fraction between 0 and 1 that specifies the probability of each unit being dropped out. A common value for the dropout rate is 0.5, but it can be tuned depending on the problem and the architecture of the model.\n",
        "\n",
        "* Dropout is implemented in Python with Keras using the `tf.keras.layers.Dropout` function, which takes the dropout rate as an argument."
      ],
      "metadata": {
        "id": "p7S9-aXFW8n7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Network and training.\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 128\n",
        "VERBOSE = 1\n",
        "NB_CLASSES = 10 # number of outputs = number of digits N_HIDDEN = 128\n",
        "VALIDATION_SPLIT = 0.2 # how much TRAIN is reserved for VALIDATION DROPOUT = 0.3\n",
        "DROPOUT = 0.3"
      ],
      "metadata": {
        "id": "oJoBZjafWV19"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading MNIST dataset.\n",
        "# Labels have one-hot representation.\n",
        "mnist = keras.datasets.mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# X_train is 60000 rows of 28x28 values; we reshape it to 60000 x 784.\n",
        "RESHAPED = 784\n",
        "\n",
        "X_train = X_train.reshape(60000, RESHAPED)\n",
        "X_test = X_test.reshape(10000, RESHAPED)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# Normalize inputs to be within in [0, 1].\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "\n",
        "# Labels have one-hot representation.\n",
        "y_train = tf.keras.utils.to_categorical(y_train, NB_CLASSES)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, NB_CLASSES)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnxLs9AZXI4a",
        "outputId": "204c5efd-da67-453c-a6bb-92cbd9ae0197"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the model.\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "model.add(\n",
        "    keras.layers.Dense(N_HIDDEN,\n",
        "    input_shape=(RESHAPED,),\n",
        "    name='dense_layer',\n",
        "    activation='relu'))\n",
        "\n",
        "model.add(\n",
        "    keras.layers.Dropout(DROPOUT))\n",
        "\n",
        "model.add(\n",
        "    keras.layers.Dense(N_HIDDEN,\n",
        "    name='dense_layer_2',\n",
        "    activation='relu'))\n",
        "\n",
        "model.add(\n",
        "    keras.layers.Dropout(DROPOUT))\n",
        "\n",
        "model.add(\n",
        "    keras.layers.Dense(NB_CLASSES,\n",
        "    name='dense_layer_3',\n",
        "    activation='softmax'))\n",
        "\n",
        "# Summary of the model.\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUdVCZL2YHkl",
        "outputId": "6619aafa-0c15-44e0-88a5-2abf38374fa4"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_layer (Dense)         (None, 128)               100480    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_layer_2 (Dense)       (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_layer_3 (Dense)       (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 118,282\n",
            "Trainable params: 118,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling the model.\n",
        "model.compile(\n",
        "    optimizer='SGD',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "FQ5xS6VxYMo0"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model.\n",
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    batch_size=BATCH_SIZE, epochs=EPOCHS,\n",
        "    verbose=VERBOSE, validation_split=VALIDATION_SPLIT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_Q4vFIIYPkb",
        "outputId": "d5f76baa-d1d0-4b53-d2af-2161a96a653f"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 1.7026 - accuracy: 0.4535 - val_loss: 0.9021 - val_accuracy: 0.8070\n",
            "Epoch 2/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.9257 - accuracy: 0.7152 - val_loss: 0.5441 - val_accuracy: 0.8653\n",
            "Epoch 3/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.7038 - accuracy: 0.7837 - val_loss: 0.4357 - val_accuracy: 0.8857\n",
            "Epoch 4/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.5988 - accuracy: 0.8204 - val_loss: 0.3748 - val_accuracy: 0.8994\n",
            "Epoch 5/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.5341 - accuracy: 0.8386 - val_loss: 0.3404 - val_accuracy: 0.9066\n",
            "Epoch 6/100\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.4903 - accuracy: 0.8521 - val_loss: 0.3159 - val_accuracy: 0.9117\n",
            "Epoch 7/100\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.4599 - accuracy: 0.8643 - val_loss: 0.2966 - val_accuracy: 0.9168\n",
            "Epoch 8/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.4327 - accuracy: 0.8716 - val_loss: 0.2822 - val_accuracy: 0.9183\n",
            "Epoch 9/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.4119 - accuracy: 0.8798 - val_loss: 0.2694 - val_accuracy: 0.9227\n",
            "Epoch 10/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.3952 - accuracy: 0.8841 - val_loss: 0.2587 - val_accuracy: 0.9261\n",
            "Epoch 11/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.3769 - accuracy: 0.8896 - val_loss: 0.2490 - val_accuracy: 0.9278\n",
            "Epoch 12/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.3645 - accuracy: 0.8928 - val_loss: 0.2403 - val_accuracy: 0.9314\n",
            "Epoch 13/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.3525 - accuracy: 0.8964 - val_loss: 0.2328 - val_accuracy: 0.9327\n",
            "Epoch 14/100\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.3415 - accuracy: 0.8999 - val_loss: 0.2259 - val_accuracy: 0.9348\n",
            "Epoch 15/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.3291 - accuracy: 0.9035 - val_loss: 0.2199 - val_accuracy: 0.9362\n",
            "Epoch 16/100\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.3193 - accuracy: 0.9073 - val_loss: 0.2144 - val_accuracy: 0.9379\n",
            "Epoch 17/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.3121 - accuracy: 0.9080 - val_loss: 0.2076 - val_accuracy: 0.9398\n",
            "Epoch 18/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.3062 - accuracy: 0.9114 - val_loss: 0.2035 - val_accuracy: 0.9411\n",
            "Epoch 19/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.2981 - accuracy: 0.9133 - val_loss: 0.1986 - val_accuracy: 0.9421\n",
            "Epoch 20/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.2912 - accuracy: 0.9140 - val_loss: 0.1938 - val_accuracy: 0.9442\n",
            "Epoch 21/100\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.2833 - accuracy: 0.9168 - val_loss: 0.1906 - val_accuracy: 0.9449\n",
            "Epoch 22/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.2784 - accuracy: 0.9185 - val_loss: 0.1858 - val_accuracy: 0.9464\n",
            "Epoch 23/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.2729 - accuracy: 0.9204 - val_loss: 0.1828 - val_accuracy: 0.9475\n",
            "Epoch 24/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.2649 - accuracy: 0.9233 - val_loss: 0.1783 - val_accuracy: 0.9484\n",
            "Epoch 25/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.2594 - accuracy: 0.9233 - val_loss: 0.1752 - val_accuracy: 0.9494\n",
            "Epoch 26/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.2563 - accuracy: 0.9240 - val_loss: 0.1720 - val_accuracy: 0.9502\n",
            "Epoch 27/100\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.2510 - accuracy: 0.9255 - val_loss: 0.1689 - val_accuracy: 0.9514\n",
            "Epoch 28/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.2464 - accuracy: 0.9273 - val_loss: 0.1675 - val_accuracy: 0.9518\n",
            "Epoch 29/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.2403 - accuracy: 0.9293 - val_loss: 0.1642 - val_accuracy: 0.9532\n",
            "Epoch 30/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.2405 - accuracy: 0.9291 - val_loss: 0.1629 - val_accuracy: 0.9535\n",
            "Epoch 31/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.2340 - accuracy: 0.9321 - val_loss: 0.1593 - val_accuracy: 0.9550\n",
            "Epoch 32/100\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.2307 - accuracy: 0.9329 - val_loss: 0.1578 - val_accuracy: 0.9556\n",
            "Epoch 33/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.2286 - accuracy: 0.9326 - val_loss: 0.1546 - val_accuracy: 0.9562\n",
            "Epoch 34/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.2246 - accuracy: 0.9338 - val_loss: 0.1522 - val_accuracy: 0.9564\n",
            "Epoch 35/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.2195 - accuracy: 0.9362 - val_loss: 0.1495 - val_accuracy: 0.9570\n",
            "Epoch 36/100\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.2181 - accuracy: 0.9366 - val_loss: 0.1479 - val_accuracy: 0.9580\n",
            "Epoch 37/100\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.2115 - accuracy: 0.9378 - val_loss: 0.1459 - val_accuracy: 0.9580\n",
            "Epoch 38/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.2115 - accuracy: 0.9379 - val_loss: 0.1444 - val_accuracy: 0.9589\n",
            "Epoch 39/100\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.2071 - accuracy: 0.9387 - val_loss: 0.1429 - val_accuracy: 0.9588\n",
            "Epoch 40/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.2058 - accuracy: 0.9399 - val_loss: 0.1402 - val_accuracy: 0.9599\n",
            "Epoch 41/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.2046 - accuracy: 0.9400 - val_loss: 0.1391 - val_accuracy: 0.9600\n",
            "Epoch 42/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.2006 - accuracy: 0.9407 - val_loss: 0.1378 - val_accuracy: 0.9603\n",
            "Epoch 43/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.2005 - accuracy: 0.9414 - val_loss: 0.1362 - val_accuracy: 0.9609\n",
            "Epoch 44/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1968 - accuracy: 0.9416 - val_loss: 0.1355 - val_accuracy: 0.9610\n",
            "Epoch 45/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1934 - accuracy: 0.9436 - val_loss: 0.1338 - val_accuracy: 0.9612\n",
            "Epoch 46/100\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.1927 - accuracy: 0.9439 - val_loss: 0.1319 - val_accuracy: 0.9623\n",
            "Epoch 47/100\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.1883 - accuracy: 0.9449 - val_loss: 0.1305 - val_accuracy: 0.9620\n",
            "Epoch 48/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1871 - accuracy: 0.9447 - val_loss: 0.1292 - val_accuracy: 0.9622\n",
            "Epoch 49/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1827 - accuracy: 0.9455 - val_loss: 0.1286 - val_accuracy: 0.9632\n",
            "Epoch 50/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1820 - accuracy: 0.9462 - val_loss: 0.1266 - val_accuracy: 0.9636\n",
            "Epoch 51/100\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.1813 - accuracy: 0.9466 - val_loss: 0.1260 - val_accuracy: 0.9630\n",
            "Epoch 52/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1792 - accuracy: 0.9472 - val_loss: 0.1248 - val_accuracy: 0.9637\n",
            "Epoch 53/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1777 - accuracy: 0.9467 - val_loss: 0.1243 - val_accuracy: 0.9643\n",
            "Epoch 54/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1759 - accuracy: 0.9486 - val_loss: 0.1235 - val_accuracy: 0.9648\n",
            "Epoch 55/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1744 - accuracy: 0.9482 - val_loss: 0.1223 - val_accuracy: 0.9648\n",
            "Epoch 56/100\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.1731 - accuracy: 0.9487 - val_loss: 0.1211 - val_accuracy: 0.9652\n",
            "Epoch 57/100\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.1683 - accuracy: 0.9495 - val_loss: 0.1199 - val_accuracy: 0.9661\n",
            "Epoch 58/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1695 - accuracy: 0.9499 - val_loss: 0.1190 - val_accuracy: 0.9658\n",
            "Epoch 59/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1671 - accuracy: 0.9509 - val_loss: 0.1183 - val_accuracy: 0.9663\n",
            "Epoch 60/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1656 - accuracy: 0.9514 - val_loss: 0.1177 - val_accuracy: 0.9664\n",
            "Epoch 61/100\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 0.1644 - accuracy: 0.9518 - val_loss: 0.1171 - val_accuracy: 0.9668\n",
            "Epoch 62/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1643 - accuracy: 0.9512 - val_loss: 0.1163 - val_accuracy: 0.9669\n",
            "Epoch 63/100\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.1602 - accuracy: 0.9523 - val_loss: 0.1152 - val_accuracy: 0.9670\n",
            "Epoch 64/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1601 - accuracy: 0.9542 - val_loss: 0.1152 - val_accuracy: 0.9673\n",
            "Epoch 65/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1553 - accuracy: 0.9546 - val_loss: 0.1136 - val_accuracy: 0.9676\n",
            "Epoch 66/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.1553 - accuracy: 0.9543 - val_loss: 0.1133 - val_accuracy: 0.9678\n",
            "Epoch 67/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1534 - accuracy: 0.9547 - val_loss: 0.1129 - val_accuracy: 0.9672\n",
            "Epoch 68/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1549 - accuracy: 0.9539 - val_loss: 0.1115 - val_accuracy: 0.9682\n",
            "Epoch 69/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1533 - accuracy: 0.9549 - val_loss: 0.1109 - val_accuracy: 0.9682\n",
            "Epoch 70/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1488 - accuracy: 0.9563 - val_loss: 0.1105 - val_accuracy: 0.9684\n",
            "Epoch 71/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.1502 - accuracy: 0.9555 - val_loss: 0.1099 - val_accuracy: 0.9688\n",
            "Epoch 72/100\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.1470 - accuracy: 0.9569 - val_loss: 0.1088 - val_accuracy: 0.9686\n",
            "Epoch 73/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1476 - accuracy: 0.9560 - val_loss: 0.1081 - val_accuracy: 0.9693\n",
            "Epoch 74/100\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.1442 - accuracy: 0.9561 - val_loss: 0.1078 - val_accuracy: 0.9696\n",
            "Epoch 75/100\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.1455 - accuracy: 0.9562 - val_loss: 0.1077 - val_accuracy: 0.9693\n",
            "Epoch 76/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1413 - accuracy: 0.9580 - val_loss: 0.1071 - val_accuracy: 0.9693\n",
            "Epoch 77/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1418 - accuracy: 0.9575 - val_loss: 0.1061 - val_accuracy: 0.9697\n",
            "Epoch 78/100\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.1399 - accuracy: 0.9589 - val_loss: 0.1056 - val_accuracy: 0.9697\n",
            "Epoch 79/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1383 - accuracy: 0.9576 - val_loss: 0.1052 - val_accuracy: 0.9706\n",
            "Epoch 80/100\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.1379 - accuracy: 0.9592 - val_loss: 0.1044 - val_accuracy: 0.9700\n",
            "Epoch 81/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.1362 - accuracy: 0.9596 - val_loss: 0.1043 - val_accuracy: 0.9711\n",
            "Epoch 82/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1340 - accuracy: 0.9600 - val_loss: 0.1033 - val_accuracy: 0.9711\n",
            "Epoch 83/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1335 - accuracy: 0.9607 - val_loss: 0.1029 - val_accuracy: 0.9709\n",
            "Epoch 84/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1366 - accuracy: 0.9595 - val_loss: 0.1028 - val_accuracy: 0.9710\n",
            "Epoch 85/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.1335 - accuracy: 0.9596 - val_loss: 0.1020 - val_accuracy: 0.9713\n",
            "Epoch 86/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1327 - accuracy: 0.9610 - val_loss: 0.1012 - val_accuracy: 0.9713\n",
            "Epoch 87/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1328 - accuracy: 0.9606 - val_loss: 0.1013 - val_accuracy: 0.9712\n",
            "Epoch 88/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1332 - accuracy: 0.9607 - val_loss: 0.1002 - val_accuracy: 0.9712\n",
            "Epoch 89/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1283 - accuracy: 0.9613 - val_loss: 0.1000 - val_accuracy: 0.9719\n",
            "Epoch 90/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.1299 - accuracy: 0.9611 - val_loss: 0.0998 - val_accuracy: 0.9718\n",
            "Epoch 91/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1290 - accuracy: 0.9619 - val_loss: 0.0993 - val_accuracy: 0.9721\n",
            "Epoch 92/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1282 - accuracy: 0.9613 - val_loss: 0.0987 - val_accuracy: 0.9722\n",
            "Epoch 93/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1268 - accuracy: 0.9626 - val_loss: 0.0987 - val_accuracy: 0.9722\n",
            "Epoch 94/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1267 - accuracy: 0.9629 - val_loss: 0.0986 - val_accuracy: 0.9722\n",
            "Epoch 95/100\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.1228 - accuracy: 0.9633 - val_loss: 0.0983 - val_accuracy: 0.9722\n",
            "Epoch 96/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1241 - accuracy: 0.9625 - val_loss: 0.0979 - val_accuracy: 0.9719\n",
            "Epoch 97/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1224 - accuracy: 0.9638 - val_loss: 0.0967 - val_accuracy: 0.9727\n",
            "Epoch 98/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1229 - accuracy: 0.9632 - val_loss: 0.0964 - val_accuracy: 0.9729\n",
            "Epoch 99/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1212 - accuracy: 0.9641 - val_loss: 0.0964 - val_accuracy: 0.9731\n",
            "Epoch 100/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1196 - accuracy: 0.9644 - val_loss: 0.0956 - val_accuracy: 0.9730\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x797e85d63ca0>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the model.\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiCJcDX7YUfJ",
        "outputId": "110a30b9-5bc1-4de7-e7de-7423cfa46766"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0932 - accuracy: 0.9725\n",
            "Test accuracy: 0.9725000262260437\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's try different optimizers\n",
        "* **Adam optimizers** are a type of optimization algorithm that are widely used in deep learning. They are based on adaptive estimation of first-order and second-order moments, which means they adjust the learning rate of each parameter according to its past gradients and momentum. Adam optimizers are known for being computationally efficient, having little memory requirement, and being well suited for large-scale problems.\n"
      ],
      "metadata": {
        "id": "shTLIdwebwou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Network and training.\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 128\n",
        "VERBOSE = 1\n",
        "NB_CLASSES = 10 # number of outputs = number of digits N_HIDDEN = 128\n",
        "VALIDATION_SPLIT = 0.2 # how much TRAIN is reserved for VALIDATION DROPOUT = 0.3\n",
        "DROPOUT = 0.3\n",
        "\n",
        "# Loading MNIST dataset.\n",
        "# Labels have one-hot representation.\n",
        "mnist = keras.datasets.mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# X_train is 60000 rows of 28x28 values; we reshape it to 60000 x 784.\n",
        "RESHAPED = 784\n",
        "\n",
        "X_train = X_train.reshape(60000, RESHAPED)\n",
        "X_test = X_test.reshape(10000, RESHAPED)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# Normalize inputs to be within in [0, 1].\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "\n",
        "# Labels have one-hot representation.\n",
        "y_train = tf.keras.utils.to_categorical(y_train, NB_CLASSES)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, NB_CLASSES)\n",
        "\n",
        "# Building the model.\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "model.add(\n",
        "    keras.layers.Dense(N_HIDDEN,\n",
        "    input_shape=(RESHAPED,),\n",
        "    name='dense_layer',\n",
        "    activation='relu'))\n",
        "\n",
        "model.add(\n",
        "    keras.layers.Dropout(DROPOUT))\n",
        "\n",
        "model.add(\n",
        "    keras.layers.Dense(N_HIDDEN,\n",
        "    name='dense_layer_2',\n",
        "    activation='relu'))\n",
        "\n",
        "model.add(\n",
        "    keras.layers.Dropout(DROPOUT))\n",
        "\n",
        "model.add(\n",
        "    keras.layers.Dense(NB_CLASSES,\n",
        "    name='dense_layer_3',\n",
        "    activation='softmax'))\n",
        "\n",
        "# Summary of the model.\n",
        "model.summary()\n",
        "\n",
        "# Compiling the model.\n",
        "model.compile(\n",
        "    optimizer='Adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(\n",
        "    'best_model.keras',\n",
        "    monitor='val_accuracy',\n",
        "    save_best_only=True,\n",
        "    mode='max')\n",
        "\n",
        "\n",
        "# Training the model.\n",
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    batch_size=BATCH_SIZE, epochs=EPOCHS,\n",
        "    verbose=VERBOSE, validation_split=VALIDATION_SPLIT,\n",
        "    callbacks = [checkpoint]\n",
        "    )\n",
        "\n",
        "\n",
        "# Evaluating the model.\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Qc002JvcCNa",
        "outputId": "582e211a-331f-44a6-8b0d-a2c6bfbf53ef"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n",
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_layer (Dense)         (None, 128)               100480    \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_layer_2 (Dense)       (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_layer_3 (Dense)       (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 118,282\n",
            "Trainable params: 118,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "375/375 [==============================] - 5s 10ms/step - loss: 0.5173 - accuracy: 0.8418 - val_loss: 0.1859 - val_accuracy: 0.9449\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.2350 - accuracy: 0.9302 - val_loss: 0.1388 - val_accuracy: 0.9603\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1788 - accuracy: 0.9466 - val_loss: 0.1154 - val_accuracy: 0.9657\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1521 - accuracy: 0.9541 - val_loss: 0.1052 - val_accuracy: 0.9697\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.1361 - accuracy: 0.9591 - val_loss: 0.0942 - val_accuracy: 0.9729\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1186 - accuracy: 0.9641 - val_loss: 0.0901 - val_accuracy: 0.9721\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.1084 - accuracy: 0.9665 - val_loss: 0.0866 - val_accuracy: 0.9740\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1001 - accuracy: 0.9689 - val_loss: 0.0878 - val_accuracy: 0.9748\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.0955 - accuracy: 0.9700 - val_loss: 0.0843 - val_accuracy: 0.9762\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0858 - accuracy: 0.9724 - val_loss: 0.0821 - val_accuracy: 0.9776\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0813 - accuracy: 0.9754\n",
            "Test accuracy: 0.9753999710083008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save the trained model"
      ],
      "metadata": {
        "id": "tE00EpmZfD7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the entire model in Keras format\n",
        "model.save('final_model.keras')"
      ],
      "metadata": {
        "id": "u67AxdCTbwKy"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.models.load_model('final_model.keras')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoGItW5SbcFo",
        "outputId": "202d8f47-5a3a-46b7-b85f-29e9f77c51bb"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.sequential.Sequential at 0x797e918e9180>"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code will create two files: `best_model.keras` and `final_model.keras`, which contain the model's architecture, weights, optimizer, and losses."
      ],
      "metadata": {
        "id": "ejF1zecPkGT7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M2YFltytjT8K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}