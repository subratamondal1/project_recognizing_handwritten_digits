{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "462fe12a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-08-24T11:19:46.456667Z",
     "iopub.status.busy": "2023-08-24T11:19:46.455771Z",
     "iopub.status.idle": "2023-08-24T11:19:46.471567Z",
     "shell.execute_reply": "2023-08-24T11:19:46.470710Z"
    },
    "papermill": {
     "duration": 0.037836,
     "end_time": "2023-08-24T11:19:46.474160",
     "exception": false,
     "start_time": "2023-08-24T11:19:46.436324",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69942d5c",
   "metadata": {
    "papermill": {
     "duration": 0.018431,
     "end_time": "2023-08-24T11:19:46.509715",
     "exception": false,
     "start_time": "2023-08-24T11:19:46.491284",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80baaf70",
   "metadata": {
    "papermill": {
     "duration": 0.016254,
     "end_time": "2023-08-24T11:19:46.543208",
     "exception": false,
     "start_time": "2023-08-24T11:19:46.526954",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## ✧ The Big Picture\n",
    "* **Get the dataset (pairs of inputs & labels)**\n",
    "* **`Forward Pass` : input ➡️ function(model) ➡️ output(prediction)** \n",
    "* **`Compute the Loss` : predictions - labels**\n",
    "* **`Backward Pass` : i.e Backpropagation**\n",
    "* **`Update the parameters` : i.e Weights & Biases**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44026e8",
   "metadata": {
    "papermill": {
     "duration": 0.016151,
     "end_time": "2023-08-24T11:19:46.576426",
     "exception": false,
     "start_time": "2023-08-24T11:19:46.560275",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MNIST data setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fcd79a",
   "metadata": {
    "papermill": {
     "duration": 0.016466,
     "end_time": "2023-08-24T11:19:46.609701",
     "exception": false,
     "start_time": "2023-08-24T11:19:46.593235",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**`dataset.py`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9f4ec14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T11:19:46.645005Z",
     "iopub.status.busy": "2023-08-24T11:19:46.644363Z",
     "iopub.status.idle": "2023-08-24T11:19:46.653978Z",
     "shell.execute_reply": "2023-08-24T11:19:46.652913Z"
    },
    "papermill": {
     "duration": 0.030728,
     "end_time": "2023-08-24T11:19:46.656800",
     "exception": false,
     "start_time": "2023-08-24T11:19:46.626072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path # Import the Path class from pathlib module\n",
    "import requests # Import the requests module for making HTTP requests\n",
    "\n",
    "def myData():\n",
    "    ### Download Dataset ###\n",
    "    data_path = Path(\"data\") # Create a Path object for the data directory\n",
    "    actual_path = data_path/\"mnist\" # Create a Path object for the mnist subdirectory\n",
    "\n",
    "    # Create the directory if it does not exist\n",
    "    actual_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    url = \"https://github.com/pytorch/tutorials/raw/main/_static/\" # The base URL for the dataset\n",
    "    file_name = \"mnist.pkl.gz\" # The file name of the dataset\n",
    "\n",
    "    # Check if the file already exists in the local directory\n",
    "    if not (actual_path/file_name).exists():\n",
    "        # If not, download the file from the URL and save it to the local directory\n",
    "        content = requests.get(url+file_name).content # Get the content of the file as bytes\n",
    "        (actual_path/file_name).open(\"wb\").write(content) # Open the file in write mode and write the content\n",
    "\n",
    "    ### Extract Dataset ###\n",
    "    import pickle # Import the pickle module for loading and saving Python objects\n",
    "    import gzip # Import the gzip module for working with compressed files\n",
    "\n",
    "    # Open the compressed file in read mode\n",
    "    with gzip.open((actual_path/file_name).as_posix(), \"rb\") as f:\n",
    "        # Load the pickle object from the file, which contains three tuples: \n",
    "        # (x_train,y_train), (x_valid,y_valid), (x_test,y_test)\n",
    "        ((x_train,y_train),(x_valid,y_valid),_) = pickle.load(file=f, encoding=\"latin-1\")\n",
    "        # We only need the first two tuples, so we ignore the third one with an underscore\n",
    "\n",
    "    return (x_train,y_train), (x_valid,y_valid) # Return the two tuples as the output of the function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3dbd2fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T11:19:46.691642Z",
     "iopub.status.busy": "2023-08-24T11:19:46.691259Z",
     "iopub.status.idle": "2023-08-24T11:19:50.417929Z",
     "shell.execute_reply": "2023-08-24T11:19:50.416705Z"
    },
    "papermill": {
     "duration": 3.747417,
     "end_time": "2023-08-24T11:19:50.420740",
     "exception": false,
     "start_time": "2023-08-24T11:19:46.673323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 784), y_train shape: (50000,)\n",
      "x_valid shape: (10000, 784), y_valid shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train,y_train), (x_valid,y_valid) = myData()\n",
    "print(f\"x_train shape: {x_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"x_valid shape: {x_valid.shape}, y_valid shape: {y_valid.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cdf3c30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T11:19:50.458174Z",
     "iopub.status.busy": "2023-08-24T11:19:50.457048Z",
     "iopub.status.idle": "2023-08-24T11:19:52.677627Z",
     "shell.execute_reply": "2023-08-24T11:19:52.676283Z"
    },
    "papermill": {
     "duration": 2.242101,
     "end_time": "2023-08-24T11:19:52.680456",
     "exception": false,
     "start_time": "2023-08-24T11:19:50.438355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/kaggle\u001b[00m\r\n",
      "├── \u001b[01;34minput\u001b[00m\r\n",
      "├── \u001b[01;34mlib\u001b[00m\r\n",
      "│   └── \u001b[01;34mkaggle\u001b[00m\r\n",
      "│       └── gcp.py\r\n",
      "├── \u001b[01;34msrc\u001b[00m\r\n",
      "│   └── script.ipynb\r\n",
      "└── \u001b[01;34mworking\u001b[00m\r\n",
      "    ├── __notebook__.ipynb\r\n",
      "    └── \u001b[01;34mdata\u001b[00m\r\n",
      "        └── \u001b[01;34mmnist\u001b[00m\r\n",
      "            └── \u001b[01;31mmnist.pkl.gz\u001b[00m\r\n",
      "\r\n",
      "7 directories, 4 files\r\n",
      "total 16M\r\n",
      "16M mnist.pkl.gz\r\n"
     ]
    }
   ],
   "source": [
    "! tree /kaggle\n",
    "! ls -sh /kaggle/working/data/mnist/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ffac06",
   "metadata": {
    "papermill": {
     "duration": 0.016439,
     "end_time": "2023-08-24T11:19:52.714810",
     "exception": false,
     "start_time": "2023-08-24T11:19:52.698371",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Exploration\n",
    "Each image is 28 x 28, and is being stored as a flattened row of length 784 (=28x28). Let’s take a look at one; we need to reshape it to 2d first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e45d92",
   "metadata": {
    "papermill": {
     "duration": 0.016682,
     "end_time": "2023-08-24T11:19:52.748336",
     "exception": false,
     "start_time": "2023-08-24T11:19:52.731654",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**`data_exploration.py`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3d55d2",
   "metadata": {
    "papermill": {
     "duration": 0.016924,
     "end_time": "2023-08-24T11:19:52.783501",
     "exception": false,
     "start_time": "2023-08-24T11:19:52.766577",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "You have to reshape the **x_train[0]** array to **(28, 28)** because the **imshow()** function expects a 2D array as input for displaying a grayscale image. The x_train[0] array is a 1D array of length 784, which represents a **flattened image of 28 by 28 pixels**. By reshaping it to (28, 28), **you are restoring the original shape of the image and making it compatible with imshow().**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26162800",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T11:19:52.822840Z",
     "iopub.status.busy": "2023-08-24T11:19:52.822374Z",
     "iopub.status.idle": "2023-08-24T11:19:53.133861Z",
     "shell.execute_reply": "2023-08-24T11:19:53.132969Z"
    },
    "papermill": {
     "duration": 0.335772,
     "end_time": "2023-08-24T11:19:53.137772",
     "exception": false,
     "start_time": "2023-08-24T11:19:52.802000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.imshow(x_train[0].reshape((28, 28)), cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acee404",
   "metadata": {
    "papermill": {
     "duration": 0.022334,
     "end_time": "2023-08-24T11:19:53.183933",
     "exception": false,
     "start_time": "2023-08-24T11:19:53.161599",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Forward Pass\n",
    "1. **initialize weights and biases (i.e parameters).**\n",
    "2. **NN architecture : input ➡️ output (simple architecture with no hidden layer)**\n",
    "     * **Number of neurons in the Input Layer is (28x28) = 784 and**\n",
    "     * **Number of neurons in the Output Layer is 10**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46941dc1",
   "metadata": {
    "papermill": {
     "duration": 0.022157,
     "end_time": "2023-08-24T11:19:53.232180",
     "exception": false,
     "start_time": "2023-08-24T11:19:53.210023",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**`model.py`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24397aa7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T11:19:53.269968Z",
     "iopub.status.busy": "2023-08-24T11:19:53.268766Z",
     "iopub.status.idle": "2023-08-24T11:19:57.819803Z",
     "shell.execute_reply": "2023-08-24T11:19:57.818447Z"
    },
    "papermill": {
     "duration": 4.573072,
     "end_time": "2023-08-24T11:19:57.822985",
     "exception": false,
     "start_time": "2023-08-24T11:19:53.249913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e51096d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T11:19:57.860918Z",
     "iopub.status.busy": "2023-08-24T11:19:57.860130Z",
     "iopub.status.idle": "2023-08-24T11:19:58.120340Z",
     "shell.execute_reply": "2023-08-24T11:19:58.119046Z"
    },
    "papermill": {
     "duration": 0.282531,
     "end_time": "2023-08-24T11:19:58.123268",
     "exception": false,
     "start_time": "2023-08-24T11:19:57.840737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([5, 0, 4,  ..., 8, 4, 8]),\n",
       " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([3, 8, 6,  ..., 5, 6, 8]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the numpy arrays to tensor\n",
    "x_train, y_train, x_valid, y_valid = map(torch.tensor, (x_train, y_train, x_valid, y_valid))\n",
    "x_train, y_train, x_valid, y_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f254bab",
   "metadata": {
    "papermill": {
     "duration": 0.019327,
     "end_time": "2023-08-24T11:19:58.160999",
     "exception": false,
     "start_time": "2023-08-24T11:19:58.141672",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. **initialize weights and biases (i.e parameters).**\n",
    "\n",
    "**`Xavier Initialization`** is a technique for initializing the weights of a neural network in a way that **preserves the variance of the inputs and outputs of each layer**. The idea is **to avoid having very small or very large values in the weights,** which **can cause vanishing or exploding gradients during training.** Xavier initialization draws the weights from a uniform distribution with a specific range, depending on the number of input and output units of each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b2bdf05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T11:19:58.206464Z",
     "iopub.status.busy": "2023-08-24T11:19:58.204739Z",
     "iopub.status.idle": "2023-08-24T11:19:58.231773Z",
     "shell.execute_reply": "2023-08-24T11:19:58.230631Z"
    },
    "papermill": {
     "duration": 0.053235,
     "end_time": "2023-08-24T11:19:58.235837",
     "exception": false,
     "start_time": "2023-08-24T11:19:58.182602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "torch.manual_seed(0)\n",
    "weights = torch.randn(784,10,requires_grad=True) / math.sqrt(784) # Xavier Initialization\n",
    "bias = torch.zeros(10,requires_grad=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5c6346",
   "metadata": {
    "papermill": {
     "duration": 0.019042,
     "end_time": "2023-08-24T11:19:58.273340",
     "exception": false,
     "start_time": "2023-08-24T11:19:58.254298",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "2. **NN architecture : input ➡️ output (simple architecture with no hidden layer)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36775e29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T11:19:58.313795Z",
     "iopub.status.busy": "2023-08-24T11:19:58.313378Z",
     "iopub.status.idle": "2023-08-24T11:19:58.318897Z",
     "shell.execute_reply": "2023-08-24T11:19:58.317337Z"
    },
    "papermill": {
     "duration": 0.029537,
     "end_time": "2023-08-24T11:19:58.322027",
     "exception": false,
     "start_time": "2023-08-24T11:19:58.292490",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model(batched_input):\n",
    "    return batched_input @ weights + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0578d750",
   "metadata": {
    "papermill": {
     "duration": 0.020314,
     "end_time": "2023-08-24T11:19:58.362387",
     "exception": false,
     "start_time": "2023-08-24T11:19:58.342073",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "3. **Loss Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b17087d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T11:19:58.403137Z",
     "iopub.status.busy": "2023-08-24T11:19:58.401927Z",
     "iopub.status.idle": "2023-08-24T11:19:58.498733Z",
     "shell.execute_reply": "2023-08-24T11:19:58.497839Z"
    },
    "papermill": {
     "duration": 0.120002,
     "end_time": "2023-08-24T11:19:58.501487",
     "exception": false,
     "start_time": "2023-08-24T11:19:58.381485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0536, 0.0503, 0.0946,  ..., 0.1342, 0.0897, 0.1038],\n",
      "        [0.0529, 0.0615, 0.1341,  ..., 0.1225, 0.0830, 0.0774],\n",
      "        [0.0952, 0.1340, 0.1113,  ..., 0.1033, 0.0914, 0.0916],\n",
      "        ...,\n",
      "        [0.0671, 0.1293, 0.0686,  ..., 0.1668, 0.1060, 0.0906],\n",
      "        [0.0626, 0.1156, 0.0831,  ..., 0.1021, 0.0638, 0.1103],\n",
      "        [0.0542, 0.0950, 0.0795,  ..., 0.1658, 0.0540, 0.1028]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "\n",
      "torch.Size([50000, 10])\n"
     ]
    }
   ],
   "source": [
    "# softmax activation function\n",
    "def softmax(x):\n",
    "    return x.exp()/x.exp().sum(-1).unsqueeze(-1)\n",
    "\n",
    "print(softmax(model(x_train)))\n",
    "print()\n",
    "print(softmax(model(x_train)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3649135",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T11:19:58.541807Z",
     "iopub.status.busy": "2023-08-24T11:19:58.540858Z",
     "iopub.status.idle": "2023-08-24T11:19:58.547391Z",
     "shell.execute_reply": "2023-08-24T11:19:58.546057Z"
    },
    "papermill": {
     "duration": 0.029309,
     "end_time": "2023-08-24T11:19:58.550151",
     "exception": false,
     "start_time": "2023-08-24T11:19:58.520842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cross Entropy Loss\n",
    "def cross_entropy_loss(preds, targets):\n",
    "    batch_size, output_features = preds.shape\n",
    "    one_hot_encode_targets = torch.eye(output_features)[targets]\n",
    "    # -1/n sum p * log(q) -> n is batch_size : sum everything and take average over the batch\n",
    "    return -(one_hot_encode_targets * softmax(preds).log()).sum()/batch_size\n",
    "\n",
    "loss_function = cross_entropy_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b90c96c",
   "metadata": {
    "papermill": {
     "duration": 0.018538,
     "end_time": "2023-08-24T11:19:58.588301",
     "exception": false,
     "start_time": "2023-08-24T11:19:58.569763",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Test if our implementation of `cross_entropy_loss` is correct or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce6c5465",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T11:19:58.628433Z",
     "iopub.status.busy": "2023-08-24T11:19:58.627950Z",
     "iopub.status.idle": "2023-08-24T11:19:58.661629Z",
     "shell.execute_reply": "2023-08-24T11:19:58.660554Z"
    },
    "papermill": {
     "duration": 0.056677,
     "end_time": "2023-08-24T11:19:58.664284",
     "exception": false,
     "start_time": "2023-08-24T11:19:58.607607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch's Function: 2.4608449935913086\n",
      "My Function: 2.4608447551727295\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "batched_x = x_train[:batch_size]\n",
    "preds = model(batched_x)\n",
    "batched_y = y_train[:batch_size]\n",
    "\n",
    "print(f\"PyTorch's Function: {F.cross_entropy(preds, batched_y)}\")\n",
    "print(f\"My Function: {cross_entropy_loss(preds, batched_y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "551eaa36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T11:19:58.701249Z",
     "iopub.status.busy": "2023-08-24T11:19:58.700854Z",
     "iopub.status.idle": "2023-08-24T11:19:58.706928Z",
     "shell.execute_reply": "2023-08-24T11:19:58.705443Z"
    },
    "papermill": {
     "duration": 0.027666,
     "end_time": "2023-08-24T11:19:58.709387",
     "exception": false,
     "start_time": "2023-08-24T11:19:58.681721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "def accuracy_function(preds, targets):\n",
    "    preds_class = torch.argmax(preds, dim = 1)\n",
    "    return (preds_class == targets).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a024218",
   "metadata": {
    "papermill": {
     "duration": 0.018796,
     "end_time": "2023-08-24T11:19:58.746881",
     "exception": false,
     "start_time": "2023-08-24T11:19:58.728085",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cae41887",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T11:19:58.785158Z",
     "iopub.status.busy": "2023-08-24T11:19:58.784760Z",
     "iopub.status.idle": "2023-08-24T11:19:58.790961Z",
     "shell.execute_reply": "2023-08-24T11:19:58.789687Z"
    },
    "papermill": {
     "duration": 0.028035,
     "end_time": "2023-08-24T11:19:58.793605",
     "exception": false,
     "start_time": "2023-08-24T11:19:58.765570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# epochs = 2\n",
    "# lr = 0.5\n",
    "# n = x_train.shape[0] # (50000, 784)\n",
    "# batch_size = 64\n",
    "# number_of_batches = n // batch_size + 1\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "#     for i in range(number_of_batches):\n",
    "#         start_idx = i * batch_size\n",
    "#         end_idx = (i + 1) * batch_size\n",
    "#         xb = x_train[start_idx:end_idx]\n",
    "#         yb = y_train[start_idx:end_idx]\n",
    "#         preds = model(xb)\n",
    "#         loss = loss_function(preds, yb)\n",
    "#         accuracy = accuracy_function(preds, yb)\n",
    "#         loss.backward() # PyTorch autograd\n",
    "        \n",
    "#         with torch.no_grad(): # temporarily sets all of the requires_grad flags to false; reduces memory consumption\n",
    "#             # update parameters (gradients/slope)\n",
    "#             weights.data -= weights.grad * lr\n",
    "#             bias.data -= bias.grad * lr\n",
    "            \n",
    "#             # reset the gradient\n",
    "#             weights.grad.zero_()\n",
    "#             bias.grad.zero_()\n",
    "            \n",
    "#             # logging\n",
    "#             if i % 100 == 0:\n",
    "#                 train_loss, train_accuracy = loss.item(), accuracy.item() * 100\n",
    "#                 print(f\"Loss: {train_loss:6f} ... Accuracy: {train_accuracy:0.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b25f19",
   "metadata": {
    "papermill": {
     "duration": 0.018209,
     "end_time": "2023-08-24T11:19:58.831012",
     "exception": false,
     "start_time": "2023-08-24T11:19:58.812803",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model with PyTorch\n",
    "## ✧ The Big Picture\n",
    "* **Dataset (Training/Validation/Test)**\n",
    "* **Build the Model**\n",
    "* **Define Loss Function & Optimizer**\n",
    "* **Define Trainer (Predictions ➡️ Compute Loss(Label - Predictions) ➡️ Backpropagation)**\n",
    "* **Define Test (on Validation set)**\n",
    "* **Run the Trainer & Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f94fa246",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T11:19:58.871112Z",
     "iopub.status.busy": "2023-08-24T11:19:58.870568Z",
     "iopub.status.idle": "2023-08-24T11:19:59.299624Z",
     "shell.execute_reply": "2023-08-24T11:19:59.297873Z"
    },
    "papermill": {
     "duration": 0.4535,
     "end_time": "2023-08-24T11:19:59.303056",
     "exception": false,
     "start_time": "2023-08-24T11:19:58.849556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ea6b5a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T11:19:59.343894Z",
     "iopub.status.busy": "2023-08-24T11:19:59.343104Z",
     "iopub.status.idle": "2023-08-24T11:20:00.464313Z",
     "shell.execute_reply": "2023-08-24T11:20:00.462801Z"
    },
    "papermill": {
     "duration": 1.144574,
     "end_time": "2023-08-24T11:20:00.467120",
     "exception": false,
     "start_time": "2023-08-24T11:19:59.322546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/kaggle\u001b[00m\r\n",
      "├── \u001b[01;34minput\u001b[00m\r\n",
      "├── \u001b[01;34mlib\u001b[00m\r\n",
      "│   └── \u001b[01;34mkaggle\u001b[00m\r\n",
      "│       └── gcp.py\r\n",
      "├── \u001b[01;34msrc\u001b[00m\r\n",
      "│   └── script.ipynb\r\n",
      "└── \u001b[01;34mworking\u001b[00m\r\n",
      "    ├── __notebook__.ipynb\r\n",
      "    └── \u001b[01;34mdata\u001b[00m\r\n",
      "        └── \u001b[01;34mmnist\u001b[00m\r\n",
      "            └── \u001b[01;31mmnist.pkl.gz\u001b[00m\r\n",
      "\r\n",
      "7 directories, 4 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree /kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375a9813",
   "metadata": {
    "papermill": {
     "duration": 0.018635,
     "end_time": "2023-08-24T11:20:00.503137",
     "exception": false,
     "start_time": "2023-08-24T11:20:00.484502",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41577da7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T11:20:00.542111Z",
     "iopub.status.busy": "2023-08-24T11:20:00.541305Z",
     "iopub.status.idle": "2023-08-24T11:20:01.891444Z",
     "shell.execute_reply": "2023-08-24T11:20:01.890200Z"
    },
    "papermill": {
     "duration": 1.372355,
     "end_time": "2023-08-24T11:20:01.894267",
     "exception": false,
     "start_time": "2023-08-24T11:20:00.521912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 82702184.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 39088639.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1648877/1648877 [00:00<00:00, 24119873.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 5141843.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_ds = MNIST(root=\"data\",train=True,download=True,transform = T.ToTensor())\n",
    "validation_ds = MNIST(root=\"data\",train=False,download=True,transform = T.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e93ff54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T11:20:01.936153Z",
     "iopub.status.busy": "2023-08-24T11:20:01.935446Z",
     "iopub.status.idle": "2023-08-24T11:20:03.059701Z",
     "shell.execute_reply": "2023-08-24T11:20:03.056618Z"
    },
    "papermill": {
     "duration": 1.149019,
     "end_time": "2023-08-24T11:20:03.062775",
     "exception": false,
     "start_time": "2023-08-24T11:20:01.913756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/kaggle\u001b[00m\r\n",
      "├── \u001b[01;34minput\u001b[00m\r\n",
      "├── \u001b[01;34mlib\u001b[00m\r\n",
      "│   └── \u001b[01;34mkaggle\u001b[00m\r\n",
      "│       └── gcp.py\r\n",
      "├── \u001b[01;34msrc\u001b[00m\r\n",
      "│   └── script.ipynb\r\n",
      "└── \u001b[01;34mworking\u001b[00m\r\n",
      "    ├── __notebook__.ipynb\r\n",
      "    └── \u001b[01;34mdata\u001b[00m\r\n",
      "        ├── \u001b[01;34mMNIST\u001b[00m\r\n",
      "        │   └── \u001b[01;34mraw\u001b[00m\r\n",
      "        │       ├── t10k-images-idx3-ubyte\r\n",
      "        │       ├── \u001b[01;31mt10k-images-idx3-ubyte.gz\u001b[00m\r\n",
      "        │       ├── t10k-labels-idx1-ubyte\r\n",
      "        │       ├── \u001b[01;31mt10k-labels-idx1-ubyte.gz\u001b[00m\r\n",
      "        │       ├── train-images-idx3-ubyte\r\n",
      "        │       ├── \u001b[01;31mtrain-images-idx3-ubyte.gz\u001b[00m\r\n",
      "        │       ├── train-labels-idx1-ubyte\r\n",
      "        │       └── \u001b[01;31mtrain-labels-idx1-ubyte.gz\u001b[00m\r\n",
      "        └── \u001b[01;34mmnist\u001b[00m\r\n",
      "            └── \u001b[01;31mmnist.pkl.gz\u001b[00m\r\n",
      "\r\n",
      "9 directories, 12 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree /kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2c22561",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T11:20:03.107247Z",
     "iopub.status.busy": "2023-08-24T11:20:03.106761Z",
     "iopub.status.idle": "2023-08-24T11:20:03.472142Z",
     "shell.execute_reply": "2023-08-24T11:20:03.470851Z"
    },
    "papermill": {
     "duration": 0.390162,
     "end_time": "2023-08-24T11:20:03.474609",
     "exception": false,
     "start_time": "2023-08-24T11:20:03.084447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([1, 28, 28])\n",
      "Label: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ef62e5cd540>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = training_ds[0]\n",
    "print(f\"Image shape: {image.shape}\")\n",
    "print(f\"Label: {label}\")\n",
    "plt.imshow(image.float().reshape(28,28), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c35399",
   "metadata": {
    "papermill": {
     "duration": 0.019589,
     "end_time": "2023-08-24T11:20:03.514166",
     "exception": false,
     "start_time": "2023-08-24T11:20:03.494577",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* Create DataLoader: it makes easy to iterate over batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c45eb636",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T11:20:03.555969Z",
     "iopub.status.busy": "2023-08-24T11:20:03.555491Z",
     "iopub.status.idle": "2023-08-24T11:20:03.593691Z",
     "shell.execute_reply": "2023-08-24T11:20:03.592194Z"
    },
    "papermill": {
     "duration": 0.062469,
     "end_time": "2023-08-24T11:20:03.596565",
     "exception": false,
     "start_time": "2023-08-24T11:20:03.534096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_ds\n",
      "torch.Size([64, 1, 28, 28])\n",
      "Flatten: torch.Size([64, 784])\n",
      "No. of Labels: 64\n",
      "tensor([4, 5, 0, 8, 3, 4, 1, 6, 5, 4, 1, 8, 3, 7, 5, 3, 2, 6, 0, 6, 6, 7, 1, 4,\n",
      "        9, 1, 0, 4, 6, 0, 5, 2, 2, 8, 1, 5, 1, 0, 2, 1, 8, 5, 4, 7, 7, 3, 7, 9,\n",
      "        8, 9, 2, 9, 1, 1, 1, 9, 7, 5, 3, 6, 5, 5, 4, 4])\n",
      "\n",
      "valid_ds\n",
      "torch.Size([64, 1, 28, 28])\n",
      "No. of Labels: 64\n",
      "tensor([6, 8, 3, 6, 5, 6, 4, 6, 7, 6, 9, 5, 1, 0, 2, 2, 5, 4, 4, 8, 3, 3, 1, 5,\n",
      "        1, 5, 1, 7, 8, 3, 8, 5, 9, 5, 2, 5, 6, 2, 1, 8, 0, 8, 5, 0, 0, 2, 5, 1,\n",
      "        8, 3, 6, 9, 2, 0, 8, 0, 9, 0, 9, 9, 2, 6, 4, 0])\n"
     ]
    }
   ],
   "source": [
    "# train_ds => (image, label) pair\n",
    "train_dl = DataLoader(dataset=training_ds,batch_size=64, shuffle=True)\n",
    "valid_dl = DataLoader(dataset=validation_ds,batch_size=64, shuffle=True)\n",
    "\n",
    "# explore train_ds\n",
    "for image, label in train_dl:\n",
    "    print(\"train_ds\")\n",
    "    print(image.shape)\n",
    "    print(f\"Flatten: {image.flatten(1,-1).shape}\")\n",
    "    print(f\"No. of Labels: {len(label)}\")\n",
    "    print(label)\n",
    "    print()\n",
    "    break\n",
    "\n",
    "# explore valid_ds\n",
    "for image, label in valid_dl:\n",
    "    print(\"valid_ds\")\n",
    "    print(image.shape)\n",
    "    print(f\"No. of Labels: {len(label)}\")\n",
    "    print(label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c010a6",
   "metadata": {
    "papermill": {
     "duration": 0.021041,
     "end_time": "2023-08-24T11:20:03.638470",
     "exception": false,
     "start_time": "2023-08-24T11:20:03.617429",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4992947f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T11:20:03.682322Z",
     "iopub.status.busy": "2023-08-24T11:20:03.681422Z",
     "iopub.status.idle": "2023-08-24T11:20:03.693354Z",
     "shell.execute_reply": "2023-08-24T11:20:03.692230Z"
    },
    "papermill": {
     "duration": 0.036975,
     "end_time": "2023-08-24T11:20:03.696704",
     "exception": false,
     "start_time": "2023-08-24T11:20:03.659729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNISTmodel(\n",
      "  (Linear): Linear(in_features=784, out_features=10, bias=True)\n",
      ")\n",
      "\n",
      "<generator object Module.parameters at 0x7ef6089c82e0>\n"
     ]
    }
   ],
   "source": [
    "class MNISTmodel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # linear layer\n",
    "        self.Linear = torch.nn.Linear(in_features= 28 * 28, out_features=10)\n",
    "        \n",
    "    def forward(self, batched_x):\n",
    "        batched_x = batched_x.flatten(1,-1) # (bs,1,28,28) => (bs,784)\n",
    "        return self.Linear(batched_x)\n",
    "     \n",
    "model = MNISTmodel()\n",
    "print(model)\n",
    "print()\n",
    "print(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45aca12",
   "metadata": {
    "papermill": {
     "duration": 0.02061,
     "end_time": "2023-08-24T11:20:03.739687",
     "exception": false,
     "start_time": "2023-08-24T11:20:03.719077",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define Loss Function & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45a882c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T11:20:03.782991Z",
     "iopub.status.busy": "2023-08-24T11:20:03.782517Z",
     "iopub.status.idle": "2023-08-24T11:20:03.790206Z",
     "shell.execute_reply": "2023-08-24T11:20:03.788964Z"
    },
    "papermill": {
     "duration": 0.032498,
     "end_time": "2023-08-24T11:20:03.792676",
     "exception": false,
     "start_time": "2023-08-24T11:20:03.760178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loss Function\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "# Optimizer\n",
    "optimizer = torch.optim.SGD(params = model.parameters(), lr = 0.5)\n",
    "\n",
    "# accuracy function for logging\n",
    "def accuracy_function(preds,yb):\n",
    "    preds_class = torch.argmax(preds, dim=1)\n",
    "    return (preds_class == yb).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e708184b",
   "metadata": {
    "papermill": {
     "duration": 0.020727,
     "end_time": "2023-08-24T11:20:03.835346",
     "exception": false,
     "start_time": "2023-08-24T11:20:03.814619",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78a67709",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T11:20:03.879517Z",
     "iopub.status.busy": "2023-08-24T11:20:03.878349Z",
     "iopub.status.idle": "2023-08-24T11:20:03.887522Z",
     "shell.execute_reply": "2023-08-24T11:20:03.886243Z"
    },
    "papermill": {
     "duration": 0.033262,
     "end_time": "2023-08-24T11:20:03.890165",
     "exception": false,
     "start_time": "2023-08-24T11:20:03.856903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_function, optimizer):\n",
    "    for batch_idx, (xb, yb) in enumerate(dataloader):\n",
    "        # prediction\n",
    "        preds = model(xb)\n",
    "        \n",
    "        # loss\n",
    "        loss = loss_function(preds, yb)\n",
    "        \n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # accuracy\n",
    "        accuracy = accuracy_function(preds,yb)\n",
    "        \n",
    "        # optimizer: updatest the parameters(weights & biases)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # logging\n",
    "        if batch_idx % 100 == 0:\n",
    "            train_loss = loss.item()\n",
    "            train_accuracy = accuracy.item() * 100\n",
    "            print(f\"Train Loss: {train_loss:6f}, Train Accuracy: {train_accuracy:0.1f}%\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70049e00",
   "metadata": {
    "papermill": {
     "duration": 0.019732,
     "end_time": "2023-08-24T11:20:03.930116",
     "exception": false,
     "start_time": "2023-08-24T11:20:03.910384",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8687e90a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T11:20:03.972350Z",
     "iopub.status.busy": "2023-08-24T11:20:03.971870Z",
     "iopub.status.idle": "2023-08-24T11:20:03.979365Z",
     "shell.execute_reply": "2023-08-24T11:20:03.977910Z"
    },
    "papermill": {
     "duration": 0.031885,
     "end_time": "2023-08-24T11:20:03.982038",
     "exception": false,
     "start_time": "2023-08-24T11:20:03.950153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define Test => Not updating any parameters (weights & biases) because we are testing\n",
    "def test(dataloader, model, loss_function):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for xb, yb in dataloader:\n",
    "            preds = model(xb)\n",
    "            loss = loss_function(preds, yb)\n",
    "            accuracy = accuracy_function(preds, yb)\n",
    "            \n",
    "            # Logging\n",
    "            test_loss = loss.item()\n",
    "            test_accuracy = accuracy.item() * 100\n",
    "        print(f\"Test Loss: {test_loss:6f}, Test Accuracy: {test_accuracy:0.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e380bb70",
   "metadata": {
    "papermill": {
     "duration": 0.021664,
     "end_time": "2023-08-24T11:20:04.027051",
     "exception": false,
     "start_time": "2023-08-24T11:20:04.005387",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Run the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e0f5019",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T11:20:04.071993Z",
     "iopub.status.busy": "2023-08-24T11:20:04.071564Z",
     "iopub.status.idle": "2023-08-24T11:20:23.086700Z",
     "shell.execute_reply": "2023-08-24T11:20:23.085413Z"
    },
    "papermill": {
     "duration": 19.040098,
     "end_time": "2023-08-24T11:20:23.089466",
     "exception": false,
     "start_time": "2023-08-24T11:20:04.049368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "-------------\n",
      "Train Loss: 2.362597, Train Accuracy: 7.8%\n",
      "Train Loss: 0.279414, Train Accuracy: 95.3%\n",
      "Train Loss: 0.498776, Train Accuracy: 79.7%\n",
      "Train Loss: 0.179664, Train Accuracy: 95.3%\n",
      "Train Loss: 0.226012, Train Accuracy: 95.3%\n",
      "Train Loss: 0.246771, Train Accuracy: 95.3%\n",
      "Train Loss: 0.348904, Train Accuracy: 92.2%\n",
      "Train Loss: 0.185858, Train Accuracy: 95.3%\n",
      "Train Loss: 0.456823, Train Accuracy: 89.1%\n",
      "Train Loss: 0.367517, Train Accuracy: 90.6%\n",
      "Test Loss: 0.223713, Test Accuracy: 93.8%\n",
      "Epoch: 1\n",
      "-------------\n",
      "Train Loss: 0.386669, Train Accuracy: 89.1%\n",
      "Train Loss: 0.345239, Train Accuracy: 89.1%\n",
      "Train Loss: 0.232453, Train Accuracy: 95.3%\n",
      "Train Loss: 0.103537, Train Accuracy: 96.9%\n",
      "Train Loss: 0.516193, Train Accuracy: 87.5%\n",
      "Train Loss: 0.462177, Train Accuracy: 82.8%\n",
      "Train Loss: 0.267572, Train Accuracy: 95.3%\n",
      "Train Loss: 0.107691, Train Accuracy: 95.3%\n",
      "Train Loss: 0.309642, Train Accuracy: 85.9%\n",
      "Train Loss: 0.152003, Train Accuracy: 93.8%\n",
      "Test Loss: 0.369485, Test Accuracy: 87.5%\n",
      "Finished !!!\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch: {epoch}\\n-------------\")\n",
    "    train(dataloader=train_dl, model = model, loss_function=loss_function, optimizer=optimizer)\n",
    "    test(dataloader=valid_dl, model = model, loss_function=loss_function)\n",
    "print(\"Finished !!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd1fadf",
   "metadata": {
    "papermill": {
     "duration": 0.021599,
     "end_time": "2023-08-24T11:20:23.133496",
     "exception": false,
     "start_time": "2023-08-24T11:20:23.111897",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## All the codes in one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f4f7cb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T11:20:23.188991Z",
     "iopub.status.busy": "2023-08-24T11:20:23.188189Z",
     "iopub.status.idle": "2023-08-24T11:20:41.708762Z",
     "shell.execute_reply": "2023-08-24T11:20:41.707702Z"
    },
    "papermill": {
     "duration": 18.554636,
     "end_time": "2023-08-24T11:20:41.711603",
     "exception": false,
     "start_time": "2023-08-24T11:20:23.156967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNISTmodel(\n",
      "  (Linear): Linear(in_features=784, out_features=10, bias=True)\n",
      ")\n",
      "Epoch: 0\n",
      "-------------\n",
      "Train Loss: 2.292282, Train Accuracy: 9.4%\n",
      "Train Loss: 0.499304, Train Accuracy: 85.9%\n",
      "Train Loss: 0.312552, Train Accuracy: 87.5%\n",
      "Train Loss: 0.457336, Train Accuracy: 90.6%\n",
      "Train Loss: 0.248651, Train Accuracy: 93.8%\n",
      "Train Loss: 0.274777, Train Accuracy: 95.3%\n",
      "Train Loss: 0.465293, Train Accuracy: 82.8%\n",
      "Train Loss: 0.296900, Train Accuracy: 92.2%\n",
      "Train Loss: 0.200728, Train Accuracy: 93.8%\n",
      "Train Loss: 0.396645, Train Accuracy: 87.5%\n",
      "Test Loss: 0.037031, Test Accuracy: 100.0%\n",
      "Epoch: 1\n",
      "-------------\n",
      "Train Loss: 0.239247, Train Accuracy: 92.2%\n",
      "Train Loss: 0.213750, Train Accuracy: 95.3%\n",
      "Train Loss: 0.322629, Train Accuracy: 82.8%\n",
      "Train Loss: 0.420863, Train Accuracy: 87.5%\n",
      "Train Loss: 0.391653, Train Accuracy: 90.6%\n",
      "Train Loss: 0.257176, Train Accuracy: 93.8%\n",
      "Train Loss: 0.085166, Train Accuracy: 96.9%\n",
      "Train Loss: 0.417168, Train Accuracy: 85.9%\n",
      "Train Loss: 0.453017, Train Accuracy: 90.6%\n",
      "Train Loss: 0.158779, Train Accuracy: 98.4%\n",
      "Test Loss: 0.151470, Test Accuracy: 93.8%\n",
      "Finished !!!\n"
     ]
    }
   ],
   "source": [
    "# Import Modules\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Download Dataset\n",
    "training_ds = MNIST(root=\"data\",train=True,download=True,transform = T.ToTensor())\n",
    "validation_ds = MNIST(root=\"data\",train=False,download=True,transform = T.ToTensor())\n",
    "\n",
    "# Create DataLoader: it makes easy to iterate over batches\n",
    "train_dl = DataLoader(dataset=training_ds,batch_size=64, shuffle=True)\n",
    "valid_dl = DataLoader(dataset=validation_ds,batch_size=64, shuffle=True)\n",
    "\n",
    "# Model Building\n",
    "class MNISTmodel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # linear layer\n",
    "        self.Linear = torch.nn.Linear(in_features= 28 * 28, out_features=10)\n",
    "        \n",
    "    def forward(self, batched_x):\n",
    "        batched_x = batched_x.flatten(1,-1) # (bs,1,28,28) => (bs,784)\n",
    "        return self.Linear(batched_x)\n",
    "     \n",
    "model = MNISTmodel()\n",
    "print(model)\n",
    "\n",
    "# Define Loss Function & Optimizer\n",
    "# Loss Function\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "# Optimizer\n",
    "optimizer = torch.optim.SGD(params = model.parameters(), lr = 0.5)\n",
    "\n",
    "# accuracy function for logging\n",
    "def accuracy_function(preds,yb):\n",
    "    preds_class = torch.argmax(preds, dim=1)\n",
    "    return (preds_class == yb).float().mean()\n",
    "\n",
    "# Trainer\n",
    "def train(dataloader, model, loss_function, optimizer):\n",
    "    for batch_idx, (xb, yb) in enumerate(dataloader):\n",
    "        # prediction\n",
    "        preds = model(xb)\n",
    "        \n",
    "        # loss\n",
    "        loss = loss_function(preds, yb)\n",
    "        \n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # accuracy\n",
    "        accuracy = accuracy_function(preds,yb)\n",
    "        \n",
    "        # optimizer: updatest the parameters(weights & biases)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # logging\n",
    "        if batch_idx % 100 == 0:\n",
    "            train_loss = loss.item()\n",
    "            train_accuracy = accuracy.item() * 100\n",
    "            print(f\"Train Loss: {train_loss:6f}, Train Accuracy: {train_accuracy:0.1f}%\")\n",
    "\n",
    "# Define tester\n",
    "# Define Test => Not updating any parameters (weights & biases) because we are testing\n",
    "def test(dataloader, model, loss_function):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for xb, yb in dataloader:\n",
    "            preds = model(xb)\n",
    "            loss = loss_function(preds, yb)\n",
    "            accuracy = accuracy_function(preds, yb)\n",
    "            \n",
    "            # Logging\n",
    "            test_loss = loss.item()\n",
    "            test_accuracy = accuracy.item() * 100\n",
    "        print(f\"Test Loss: {test_loss:6f}, Test Accuracy: {test_accuracy:0.1f}%\")\n",
    "        \n",
    "# Run the Model\n",
    "epochs = 2\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch: {epoch}\\n-------------\")\n",
    "    train(dataloader=train_dl, model = model, loss_function=loss_function, optimizer=optimizer)\n",
    "    test(dataloader=valid_dl, model = model, loss_function=loss_function)\n",
    "print(\"Finished !!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc3e7bf2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T11:20:41.761983Z",
     "iopub.status.busy": "2023-08-24T11:20:41.761343Z",
     "iopub.status.idle": "2023-08-24T11:20:59.961105Z",
     "shell.execute_reply": "2023-08-24T11:20:59.959771Z"
    },
    "papermill": {
     "duration": 18.228252,
     "end_time": "2023-08-24T11:20:59.964028",
     "exception": false,
     "start_time": "2023-08-24T11:20:41.735776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "-------------\n",
      "Train Loss: 0.376511, Train Accuracy: 89.1%\n",
      "Test Loss: 0.309095, Test Accuracy: 91.1%\n",
      "Epoch: 1\n",
      "-------------\n",
      "Train Loss: 0.303807, Train Accuracy: 91.3%\n",
      "Test Loss: 0.289162, Test Accuracy: 91.9%\n",
      "Finished !!!\n"
     ]
    }
   ],
   "source": [
    "# Import Modules\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# Download Dataset\n",
    "training_ds = MNIST(root=\"data\",train=True,download=True,transform = T.ToTensor())\n",
    "validation_ds = MNIST(root=\"data\",train=False,download=True,transform = T.ToTensor())\n",
    "\n",
    "# Create DataLoader: it makes easy to iterate over batches\n",
    "train_dl = DataLoader(dataset=training_ds,batch_size=64, shuffle=True)\n",
    "valid_dl = DataLoader(dataset=validation_ds,batch_size=64, shuffle=True)\n",
    "\n",
    "# Model Building\n",
    "class MNISTmodel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # linear layer\n",
    "        self.Linear = torch.nn.Linear(in_features= 28 * 28, out_features=10)\n",
    "        \n",
    "    def forward(self, batched_x):\n",
    "        batched_x = batched_x.flatten(1,-1) # (bs,1,28,28) => (bs,784)\n",
    "        return self.Linear(batched_x)\n",
    "     \n",
    "model = MNISTmodel()\n",
    "\n",
    "# Define Loss Function & Optimizer\n",
    "# Loss Function\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "# Optimizer\n",
    "optimizer = torch.optim.SGD(params = model.parameters(), lr = 0.5)\n",
    "\n",
    "# accuracy function for logging\n",
    "def accuracy_function(preds,yb):\n",
    "    preds_class = torch.argmax(preds, dim=1)\n",
    "    return (preds_class == yb).float().mean()\n",
    "\n",
    "# Trainer\n",
    "def train(dataloader, model, loss_function, optimizer):\n",
    "    model.train() # set the model to training mode\n",
    "    total_loss = 0 # initialize the total loss to zero\n",
    "    total_accuracy = 0 # initialize the total accuracy to zero\n",
    "    for batch_idx, (xb, yb) in enumerate(dataloader):\n",
    "        # prediction\n",
    "        preds = model(xb)\n",
    "        \n",
    "        # loss\n",
    "        loss = loss_function(preds, yb)\n",
    "        \n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # accuracy\n",
    "        accuracy = accuracy_function(preds,yb)\n",
    "        \n",
    "        # optimizer: updatest the parameters(weights & biases)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # update the total loss and accuracy\n",
    "        total_loss += loss.item()\n",
    "        total_accuracy += accuracy.item()\n",
    "        \n",
    "    # calculate the average loss and accuracy over the epoch\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_accuracy = total_accuracy / len(dataloader) * 100\n",
    "    \n",
    "    # logging\n",
    "    print(f\"Train Loss: {avg_loss:6f}, Train Accuracy: {avg_accuracy:0.1f}%\")\n",
    "\n",
    "# Define tester\n",
    "# Define Test => Not updating any parameters (weights & biases) because we are testing\n",
    "def test(dataloader, model, loss_function):\n",
    "    model.eval() # set the model to evaluation mode\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        total_loss = 0 # initialize the total loss to zero\n",
    "        total_accuracy = 0 # initialize the total accuracy to zero\n",
    "        \n",
    "        for xb, yb in dataloader:\n",
    "            preds = model(xb)\n",
    "            loss = loss_function(preds, yb)\n",
    "            accuracy = accuracy_function(preds, yb)\n",
    "            \n",
    "            # update the total loss and accuracy\n",
    "            total_loss += loss.item()\n",
    "            total_accuracy += accuracy.item()\n",
    "            \n",
    "        # calculate the average loss and accuracy over the epoch    \n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        avg_accuracy = total_accuracy / len(dataloader) * 100\n",
    "        \n",
    "        # Logging\n",
    "        print(f\"Test Loss: {avg_loss:6f}, Test Accuracy: {avg_accuracy:0.1f}%\")\n",
    "        \n",
    "# Run the Model\n",
    "epochs = 2\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch: {epoch}\\n-------------\")\n",
    "    train(dataloader=train_dl, model = model, loss_function=loss_function, optimizer=optimizer)\n",
    "    test(dataloader=valid_dl, model = model, loss_function=loss_function)\n",
    "print(\"Finished !!!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9709c919",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T11:21:00.018712Z",
     "iopub.status.busy": "2023-08-24T11:21:00.018298Z",
     "iopub.status.idle": "2023-08-24T11:21:46.191900Z",
     "shell.execute_reply": "2023-08-24T11:21:46.189510Z"
    },
    "papermill": {
     "duration": 46.206365,
     "end_time": "2023-08-24T11:21:46.194767",
     "exception": false,
     "start_time": "2023-08-24T11:20:59.988402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "-------------\n",
      "Train Loss: 0.375370, Train Accuracy: 89.1%\n",
      "Test Loss: 0.305088, Test Accuracy: 91.3%\n",
      "Epoch: 1\n",
      "-------------\n",
      "Train Loss: 0.304085, Train Accuracy: 91.4%\n",
      "Test Loss: 0.306357, Test Accuracy: 90.6%\n",
      "Epoch: 2\n",
      "-------------\n",
      "Train Loss: 0.291914, Train Accuracy: 91.7%\n",
      "Test Loss: 0.285979, Test Accuracy: 92.0%\n",
      "Epoch: 3\n",
      "-------------\n",
      "Train Loss: 0.285942, Train Accuracy: 92.0%\n",
      "Test Loss: 0.295958, Test Accuracy: 91.4%\n",
      "Epoch: 4\n",
      "-------------\n",
      "Train Loss: 0.281135, Train Accuracy: 92.1%\n",
      "Test Loss: 0.304136, Test Accuracy: 91.5%\n",
      "Finished !!!\n"
     ]
    }
   ],
   "source": [
    "# Import Modules\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# Define a function to preprocess an image and return a tensor\n",
    "def preprocess_image(image):\n",
    "    # Convert the image to grayscale\n",
    "    image = image.convert(\"L\")\n",
    "    # Resize the image to 28x28 pixels\n",
    "    image = image.resize((28, 28))\n",
    "    # Transform the image to a tensor\n",
    "    image = T.ToTensor()(image)\n",
    "    # Add a batch dimension\n",
    "    image = image.unsqueeze(0)\n",
    "    return image\n",
    "\n",
    "# Define a function to predict the class of an image using the model\n",
    "def predict(image):\n",
    "    # Preprocess the image\n",
    "    image = preprocess_image(image)\n",
    "    # Get the model output\n",
    "    output = model(image)\n",
    "    # Get the predicted class\n",
    "    pred = torch.argmax(output, dim=1)\n",
    "    return pred.item()\n",
    "\n",
    "# Download Dataset\n",
    "training_ds = MNIST(root=\"data\",train=True,download=True,transform = T.ToTensor())\n",
    "validation_ds = MNIST(root=\"data\",train=False,download=True,transform = T.ToTensor())\n",
    "\n",
    "# Create DataLoader: it makes easy to iterate over batches\n",
    "train_dl = DataLoader(dataset=training_ds,batch_size=64, shuffle=True)\n",
    "valid_dl = DataLoader(dataset=validation_ds,batch_size=64, shuffle=True)\n",
    "\n",
    "# Model Building\n",
    "class MNISTmodel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # linear layer\n",
    "        self.Linear = torch.nn.Linear(in_features= 28 * 28, out_features=10)\n",
    "        \n",
    "    def forward(self, batched_x):\n",
    "        batched_x = batched_x.flatten(1,-1) # (bs,1,28,28) => (bs,784)\n",
    "        return self.Linear(batched_x)\n",
    "     \n",
    "model = MNISTmodel()\n",
    "\n",
    "# Define Loss Function & Optimizer\n",
    "# Loss Function\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "# Optimizer\n",
    "optimizer = torch.optim.SGD(params = model.parameters(), lr = 0.5)\n",
    "\n",
    "# accuracy function for logging\n",
    "def accuracy_function(preds,yb):\n",
    "    preds_class = torch.argmax(preds, dim=1)\n",
    "    return (preds_class == yb).float().mean()\n",
    "\n",
    "# Trainer\n",
    "def train(dataloader, model, loss_function, optimizer):\n",
    "    model.train() # set the model to training mode\n",
    "    total_loss = 0 # initialize the total loss to zero\n",
    "    total_accuracy = 0 # initialize the total accuracy to zero\n",
    "    for batch_idx, (xb, yb) in enumerate(dataloader):\n",
    "        # prediction\n",
    "        preds = model(xb)\n",
    "        \n",
    "        # loss\n",
    "        loss = loss_function(preds, yb)\n",
    "        \n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # accuracy\n",
    "        accuracy = accuracy_function(preds,yb)\n",
    "        \n",
    "        # optimizer: updatest the parameters(weights & biases)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # update the total loss and accuracy\n",
    "        total_loss += loss.item()\n",
    "        total_accuracy += accuracy.item()\n",
    "        \n",
    "    # calculate the average loss and accuracy over the epoch\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_accuracy = total_accuracy / len(dataloader) * 100\n",
    "    \n",
    "    # logging\n",
    "    print(f\"Train Loss: {avg_loss:6f}, Train Accuracy: {avg_accuracy:0.1f}%\")\n",
    "\n",
    "# Define tester\n",
    "# Define Test => Not updating any parameters (weights & biases) because we are testing\n",
    "def test(dataloader, model, loss_function):\n",
    "    model.eval() # set the model to evaluation mode\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        total_loss = 0 # initialize the total loss to zero\n",
    "        total_accuracy = 0 # initialize the total accuracy to zero\n",
    "        \n",
    "        for xb, yb in dataloader:\n",
    "            preds = model(xb)\n",
    "            loss = loss_function(preds, yb)\n",
    "            accuracy = accuracy_function(preds, yb)\n",
    "            \n",
    "            # update the total loss and accuracy\n",
    "            total_loss += loss.item()\n",
    "            total_accuracy += accuracy.item()\n",
    "            \n",
    "        # calculate the average loss and accuracy over the epoch    \n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        avg_accuracy = total_accuracy / len(dataloader) * 100\n",
    "        \n",
    "        # Logging\n",
    "        print(f\"Test Loss: {avg_loss:6f}, Test Accuracy: {avg_accuracy:0.1f}%\")\n",
    "        \n",
    "# Run the Model\n",
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch: {epoch}\\n-------------\")\n",
    "    train(dataloader=train_dl, model = model, loss_function=loss_function, optimizer=optimizer)\n",
    "    test(dataloader=valid_dl, model = model, loss_function=loss_function)\n",
    "print(\"Finished !!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cbd6aec6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T11:21:46.248202Z",
     "iopub.status.busy": "2023-08-24T11:21:46.247743Z",
     "iopub.status.idle": "2023-08-24T11:21:47.662059Z",
     "shell.execute_reply": "2023-08-24T11:21:47.660160Z"
    },
    "papermill": {
     "duration": 1.444377,
     "end_time": "2023-08-24T11:21:47.665452",
     "exception": false,
     "start_time": "2023-08-24T11:21:46.221075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-08-24 11:21:47--  https://th.bing.com/th/id/OIP.nQO9ZHqT_jnXkFoyFxy4ygHaKE?w=159&h=216&c=7&r=0&o=5&dpr=2&pid=1.7\r\n",
      "Resolving th.bing.com (th.bing.com)... 23.46.63.51, 23.46.63.74, 23.46.63.48, ...\r\n",
      "Connecting to th.bing.com (th.bing.com)|23.46.63.51|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 19708 (19K) [image/jpeg]\r\n",
      "Saving to: ‘digit.jpg’\r\n",
      "\r\n",
      "digit.jpg           100%[===================>]  19.25K  --.-KB/s    in 0.001s  \r\n",
      "\r\n",
      "2023-08-24 11:21:47 (22.5 MB/s) - ‘digit.jpg’ saved [19708/19708]\r\n",
      "\r\n",
      "The predicted class is 2\n"
     ]
    }
   ],
   "source": [
    "# Now you can use the predict function to get the class of any image\n",
    "# For example, if you have an image named \"digit.jpg\" in your current directory, you can do this:\n",
    "from PIL import Image\n",
    "! wget -O \"digit.jpg\" \"https://th.bing.com/th/id/OIP.nQO9ZHqT_jnXkFoyFxy4ygHaKE?w=159&h=216&c=7&r=0&o=5&dpr=2&pid=1.7\"\n",
    "image = Image.open(\"digit.jpg\")\n",
    "pred = predict(image)\n",
    "print(f\"The predicted class is {pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6690cd1",
   "metadata": {
    "papermill": {
     "duration": 0.025507,
     "end_time": "2023-08-24T11:21:47.717302",
     "exception": false,
     "start_time": "2023-08-24T11:21:47.691795",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model with PyTorch Lightning\n",
    "## ✧ The Big Picture\n",
    "* **Dataset (Training/Validation/Test)**\n",
    "* **Build the Model**\n",
    "* **Define Loss Function & Optimizer**\n",
    "* **Define Trainer (Predictions ➡️ Compute Loss(Label - Predictions) ➡️ Backpropagation)**\n",
    "* **Define Test (on Validation set)**\n",
    "* **Run the Trainer & Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a2b68b71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T11:21:47.773479Z",
     "iopub.status.busy": "2023-08-24T11:21:47.773072Z",
     "iopub.status.idle": "2023-08-24T11:22:09.050298Z",
     "shell.execute_reply": "2023-08-24T11:22:09.048876Z"
    },
    "papermill": {
     "duration": 21.310756,
     "end_time": "2023-08-24T11:22:09.053771",
     "exception": false,
     "start_time": "2023-08-24T11:21:47.743015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightning\r\n",
      "  Downloading lightning-2.0.7-py3-none-any.whl (1.9 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: Jinja2<5.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (3.1.2)\r\n",
      "Requirement already satisfied: PyYAML<8.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (6.0)\r\n",
      "Requirement already satisfied: arrow<3.0,>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.2.3)\r\n",
      "Requirement already satisfied: backoff<4.0,>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from lightning) (2.2.1)\r\n",
      "Requirement already satisfied: beautifulsoup4<6.0,>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.12.2)\r\n",
      "Requirement already satisfied: click<10.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (8.1.3)\r\n",
      "Collecting croniter<1.5.0,>=1.3.0 (from lightning)\r\n",
      "  Downloading croniter-1.4.1-py2.py3-none-any.whl (19 kB)\r\n",
      "Collecting dateutils<2.0 (from lightning)\r\n",
      "  Downloading dateutils-0.6.12-py2.py3-none-any.whl (5.7 kB)\r\n",
      "Collecting deepdiff<8.0,>=5.7.0 (from lightning)\r\n",
      "  Downloading deepdiff-6.3.1-py3-none-any.whl (70 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.7/70.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: fastapi<2.0,>=0.92.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (0.98.0)\r\n",
      "Requirement already satisfied: fsspec<2025.0,>=2022.5.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (2023.6.0)\r\n",
      "Collecting inquirer<5.0,>=2.10.0 (from lightning)\r\n",
      "  Downloading inquirer-3.1.3-py3-none-any.whl (18 kB)\r\n",
      "Collecting lightning-cloud>=0.5.37 (from lightning)\r\n",
      "  Downloading lightning_cloud-0.5.37-py3-none-any.whl (596 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m596.7/596.7 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: lightning-utilities<2.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (0.9.0)\r\n",
      "Requirement already satisfied: numpy<3.0,>=1.17.2 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.23.5)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from lightning) (21.3)\r\n",
      "Requirement already satisfied: psutil<7.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (5.9.3)\r\n",
      "Requirement already satisfied: pydantic<2.2.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.10.9)\r\n",
      "Collecting python-multipart<2.0,>=0.0.5 (from lightning)\r\n",
      "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: requests<4.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (2.31.0)\r\n",
      "Requirement already satisfied: rich<15.0,>=12.3.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (13.4.2)\r\n",
      "Requirement already satisfied: starlette in /opt/conda/lib/python3.10/site-packages (from lightning) (0.27.0)\r\n",
      "Collecting starsessions<2.0,>=1.2.1 (from lightning)\r\n",
      "  Downloading starsessions-1.3.0-py3-none-any.whl (10 kB)\r\n",
      "Requirement already satisfied: torch<4.0,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (2.0.0+cpu)\r\n",
      "Requirement already satisfied: torchmetrics<2.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.0.0)\r\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.65.0)\r\n",
      "Requirement already satisfied: traitlets<7.0,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (5.9.0)\r\n",
      "Requirement already satisfied: typing-extensions<6.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.6.3)\r\n",
      "Requirement already satisfied: urllib3<4.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.26.15)\r\n",
      "Requirement already satisfied: uvicorn<2.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (0.22.0)\r\n",
      "Requirement already satisfied: websocket-client<3.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.6.0)\r\n",
      "Requirement already satisfied: websockets<13.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (11.0.3)\r\n",
      "Requirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.10/site-packages (from lightning) (2.0.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7.0 in /opt/conda/lib/python3.10/site-packages (from arrow<3.0,>=1.2.0->lightning) (2.8.2)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4<6.0,>=4.8.0->lightning) (2.3.2.post1)\r\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.10/site-packages (from dateutils<2.0->lightning) (2023.3)\r\n",
      "Collecting ordered-set<4.2.0,>=4.0.2 (from deepdiff<8.0,>=5.7.0->lightning)\r\n",
      "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\r\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec<2025.0,>=2022.5.0->lightning) (3.8.4)\r\n",
      "Requirement already satisfied: blessed>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from inquirer<5.0,>=2.10.0->lightning) (1.20.0)\r\n",
      "Collecting python-editor>=1.0.4 (from inquirer<5.0,>=2.10.0->lightning)\r\n",
      "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\r\n",
      "Collecting readchar>=3.0.6 (from inquirer<5.0,>=2.10.0->lightning)\r\n",
      "  Downloading readchar-4.0.5-py3-none-any.whl (8.5 kB)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2<5.0->lightning) (2.1.3)\r\n",
      "Requirement already satisfied: pyjwt in /opt/conda/lib/python3.10/site-packages (from lightning-cloud>=0.5.37->lightning) (2.7.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from lightning-cloud>=0.5.37->lightning) (1.16.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->lightning) (3.0.9)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<4.0->lightning) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<4.0->lightning) (3.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<4.0->lightning) (2023.5.7)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich<15.0,>=12.3.0->lightning) (2.2.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich<15.0,>=12.3.0->lightning) (2.15.1)\r\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/lib/python3.10/site-packages (from starlette->lightning) (3.7.0)\r\n",
      "Requirement already satisfied: itsdangerous<3.0.0,>=2.0.1 in /opt/conda/lib/python3.10/site-packages (from starsessions<2.0,>=1.2.1->lightning) (2.1.2)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.11.0->lightning) (3.12.2)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.11.0->lightning) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.11.0->lightning) (3.1)\r\n",
      "Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn<2.0->lightning) (0.14.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning) (23.1.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning) (6.0.4)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning) (4.0.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning) (1.9.2)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning) (1.3.3)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning) (1.3.1)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette->lightning) (1.3.0)\r\n",
      "Requirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette->lightning) (1.1.1)\r\n",
      "Requirement already satisfied: wcwidth>=0.1.4 in /opt/conda/lib/python3.10/site-packages (from blessed>=1.19.0->inquirer<5.0,>=2.10.0->lightning) (0.2.6)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<15.0,>=12.3.0->lightning) (0.1.2)\r\n",
      "Requirement already satisfied: setuptools>=41.0 in /opt/conda/lib/python3.10/site-packages (from readchar>=3.0.6->inquirer<5.0,>=2.10.0->lightning) (59.8.0)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch<4.0,>=1.11.0->lightning) (1.3.0)\r\n",
      "Installing collected packages: python-editor, readchar, python-multipart, ordered-set, inquirer, deepdiff, dateutils, croniter, starsessions, lightning-cloud, lightning\r\n",
      "Successfully installed croniter-1.4.1 dateutils-0.6.12 deepdiff-6.3.1 inquirer-3.1.3 lightning-2.0.7 lightning-cloud-0.5.37 ordered-set-4.1.0 python-editor-1.0.4 python-multipart-0.0.6 readchar-4.0.5 starsessions-1.3.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e8933d64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T11:22:09.114997Z",
     "iopub.status.busy": "2023-08-24T11:22:09.114546Z",
     "iopub.status.idle": "2023-08-24T11:22:23.978140Z",
     "shell.execute_reply": "2023-08-24T11:22:23.976896Z"
    },
    "papermill": {
     "duration": 14.89802,
     "end_time": "2023-08-24T11:22:23.981210",
     "exception": false,
     "start_time": "2023-08-24T11:22:09.083190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "# Import Modules\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as T\n",
    "import pytorch_lightning as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dec66494",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T11:22:24.044445Z",
     "iopub.status.busy": "2023-08-24T11:22:24.044042Z",
     "iopub.status.idle": "2023-08-24T11:22:27.386534Z",
     "shell.execute_reply": "2023-08-24T11:22:27.384902Z"
    },
    "papermill": {
     "duration": 3.377162,
     "end_time": "2023-08-24T11:22:27.390573",
     "exception": true,
     "start_time": "2023-08-24T11:22:24.013411",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">39</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">36 </span>trainer = L.Trainer(max_epochs=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">5</span>)                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">37 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">38 # train model</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>39 trainer.fit(model, train_dl)                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">40 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">531</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">fit</span>          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 528 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 529 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>model = _maybe_unwrap_optimized(model)                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 530 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.strategy._lightning_module = model                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 531 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>call._call_and_handle_interrupt(                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 532 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._fit_impl, model, train_dataloaders, val_dataloaders, datamodule,  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 533 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 534 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">call.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">42</span> in                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_and_handle_interrupt</span>                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 39 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 40 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> trainer.strategy.launcher <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 41 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer,    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 42 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> trainer_fn(*args, **kwargs)                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 43 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 44 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> _TunerExitException:                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 45 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>_call_teardown_hook(trainer)                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">570</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_fit_impl</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 567 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>model_provided=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>,                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 568 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>model_connected=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.lightning_module <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>,                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 569 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 570 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._run(model, ckpt_path=ckpt_path)                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 571 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 572 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">assert</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.state.stopped                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 573 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.training = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">951</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_run</span>         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 948 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._logger_connector.reset_metrics()                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 949 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 950 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># strategy will configure model and move it to the device</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 951 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.strategy.setup(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>)                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 952 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 953 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># hook</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 954 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.state.fn == TrainerFn.FITTING:                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/pytorch_lightning/strategies/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">single_device.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">75</span> in      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">setup</span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">72 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">73 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">setup</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, trainer: pl.Trainer) -&gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">74 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.model_to_device()                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>75 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">super</span>().setup(trainer)                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">76 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">77 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">@property</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">78 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">is_global_zero</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>) -&gt; <span style=\"color: #00ffff; text-decoration-color: #00ffff\">bool</span>:                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/pytorch_lightning/strategies/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">strategy.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">149</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">setup</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">146 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">147 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">assert</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.accelerator <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">148 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.accelerator.setup(trainer)                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>149 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.setup_optimizers(trainer)                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">150 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.setup_precision_plugin()                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">151 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>_optimizers_to_device(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.optimizers, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.root_device)                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">152 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/pytorch_lightning/strategies/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">strategy.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">139</span> in          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">setup_optimizers</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">136 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> trainer.state.fn != TrainerFn.FITTING:                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">137 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span>                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">138 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">assert</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.lightning_module <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>139 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.optimizers, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.lr_scheduler_configs = _init_optimizers_and_lr_schedulers(   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">140 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">141 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">setup</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, trainer: <span style=\"color: #808000; text-decoration-color: #808000\">\"pl.Trainer\"</span>) -&gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">142 </span><span style=\"color: #bfbfbf; text-decoration-color: #bfbfbf\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"Setup plugins for the trainer fit and creates optimizers.</span>                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/pytorch_lightning/core/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">optimizer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">168</span> in               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_init_optimizers_and_lr_schedulers</span>                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">165 </span><span style=\"color: #bfbfbf; text-decoration-color: #bfbfbf\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"Calls `LightningModule.configure_optimizers` and parses and validates the output.</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">166 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">pytorch_lightning.trainer</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> call                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">167 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>168 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>optim_conf = call._call_lightning_module_hook(model.trainer, <span style=\"color: #808000; text-decoration-color: #808000\">\"configure_optimizers\"</span>,   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">169 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">170 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> optim_conf <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">171 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>rank_zero_warn(                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">call.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">140</span> in                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_lightning_module_hook</span>                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">137 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>pl_module._current_fx_name = hook_name                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">138 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">139 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> trainer.profiler.profile(<span style=\"color: #808000; text-decoration-color: #808000\">f\"[LightningModule]{</span>pl_module.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__class__</span>.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span><span style=\"color: #808000; text-decoration-color: #808000\">}.{</span>hoo   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>140 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>output = fn(*args, **kwargs)                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">141 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">142 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># restore current_fx when nested context</span>                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">143 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>pl_module._current_fx_name = prev_fx_name                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">configure_optimizers</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">29</span>                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">26 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> loss                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">27 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">28 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">configure_optimizers</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>):                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>29 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> torch.optim.SGD(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.parameters(), lr = lr)                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">30 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31 # train model</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">32 # initialize model</span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'lr'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m39\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m36 \u001b[0mtrainer = L.Trainer(max_epochs=\u001b[94m5\u001b[0m)                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m37 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m38 \u001b[0m\u001b[2m# train model\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m39 trainer.fit(model, train_dl)                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m40 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m531\u001b[0m in \u001b[92mfit\u001b[0m          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 528 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 529 \u001b[0m\u001b[2m│   │   \u001b[0mmodel = _maybe_unwrap_optimized(model)                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 530 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.strategy._lightning_module = model                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 531 \u001b[2m│   │   \u001b[0mcall._call_and_handle_interrupt(                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 532 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m, \u001b[96mself\u001b[0m._fit_impl, model, train_dataloaders, val_dataloaders, datamodule,  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 533 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 534 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/\u001b[0m\u001b[1;33mcall.py\u001b[0m:\u001b[94m42\u001b[0m in                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_call_and_handle_interrupt\u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 39 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mtry\u001b[0m:                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 40 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m trainer.strategy.launcher \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 41 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer,    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 42 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m trainer_fn(*args, **kwargs)                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 43 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 44 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mexcept\u001b[0m _TunerExitException:                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 45 \u001b[0m\u001b[2m│   │   \u001b[0m_call_teardown_hook(trainer)                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m570\u001b[0m in \u001b[92m_fit_impl\u001b[0m    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 567 \u001b[0m\u001b[2m│   │   │   \u001b[0mmodel_provided=\u001b[94mTrue\u001b[0m,                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 568 \u001b[0m\u001b[2m│   │   │   \u001b[0mmodel_connected=\u001b[96mself\u001b[0m.lightning_module \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m,                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 569 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 570 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._run(model, ckpt_path=ckpt_path)                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 571 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 572 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94massert\u001b[0m \u001b[96mself\u001b[0m.state.stopped                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 573 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.training = \u001b[94mFalse\u001b[0m                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m951\u001b[0m in \u001b[92m_run\u001b[0m         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 948 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._logger_connector.reset_metrics()                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 949 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 950 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# strategy will configure model and move it to the device\u001b[0m                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 951 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.strategy.setup(\u001b[96mself\u001b[0m)                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 952 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 953 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# hook\u001b[0m                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 954 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.state.fn == TrainerFn.FITTING:                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/strategies/\u001b[0m\u001b[1;33msingle_device.py\u001b[0m:\u001b[94m75\u001b[0m in      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92msetup\u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m72 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m73 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92msetup\u001b[0m(\u001b[96mself\u001b[0m, trainer: pl.Trainer) -> \u001b[94mNone\u001b[0m:                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m74 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.model_to_device()                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m75 \u001b[2m│   │   \u001b[0m\u001b[96msuper\u001b[0m().setup(trainer)                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m76 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m77 \u001b[0m\u001b[2m│   \u001b[0m\u001b[1;95m@property\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m78 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mis_global_zero\u001b[0m(\u001b[96mself\u001b[0m) -> \u001b[96mbool\u001b[0m:                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/strategies/\u001b[0m\u001b[1;33mstrategy.py\u001b[0m:\u001b[94m149\u001b[0m in \u001b[92msetup\u001b[0m    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m146 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m147 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94massert\u001b[0m \u001b[96mself\u001b[0m.accelerator \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m148 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.accelerator.setup(trainer)                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m149 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.setup_optimizers(trainer)                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m150 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.setup_precision_plugin()                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m151 \u001b[0m\u001b[2m│   │   \u001b[0m_optimizers_to_device(\u001b[96mself\u001b[0m.optimizers, \u001b[96mself\u001b[0m.root_device)                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m152 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/strategies/\u001b[0m\u001b[1;33mstrategy.py\u001b[0m:\u001b[94m139\u001b[0m in          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92msetup_optimizers\u001b[0m                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m136 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m trainer.state.fn != TrainerFn.FITTING:                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m137 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m138 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94massert\u001b[0m \u001b[96mself\u001b[0m.lightning_module \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m139 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.optimizers, \u001b[96mself\u001b[0m.lr_scheduler_configs = _init_optimizers_and_lr_schedulers(   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m140 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m141 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92msetup\u001b[0m(\u001b[96mself\u001b[0m, trainer: \u001b[33m\"\u001b[0m\u001b[33mpl.Trainer\u001b[0m\u001b[33m\"\u001b[0m) -> \u001b[94mNone\u001b[0m:                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m142 \u001b[0m\u001b[2;90m│   │   \u001b[0m\u001b[33m\"\"\"Setup plugins for the trainer fit and creates optimizers.\u001b[0m                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/core/\u001b[0m\u001b[1;33moptimizer.py\u001b[0m:\u001b[94m168\u001b[0m in               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_init_optimizers_and_lr_schedulers\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m165 \u001b[0m\u001b[2;90m│   \u001b[0m\u001b[33m\"\"\"Calls `LightningModule.configure_optimizers` and parses and validates the output.\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m166 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mfrom\u001b[0m \u001b[4;96mpytorch_lightning\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mtrainer\u001b[0m \u001b[94mimport\u001b[0m call                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m167 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m168 \u001b[2m│   \u001b[0moptim_conf = call._call_lightning_module_hook(model.trainer, \u001b[33m\"\u001b[0m\u001b[33mconfigure_optimizers\u001b[0m\u001b[33m\"\u001b[0m,   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m169 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m170 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m optim_conf \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m171 \u001b[0m\u001b[2m│   │   \u001b[0mrank_zero_warn(                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/\u001b[0m\u001b[1;33mcall.py\u001b[0m:\u001b[94m140\u001b[0m in                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_call_lightning_module_hook\u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m137 \u001b[0m\u001b[2m│   \u001b[0mpl_module._current_fx_name = hook_name                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m138 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m139 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mwith\u001b[0m trainer.profiler.profile(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m[LightningModule]\u001b[0m\u001b[33m{\u001b[0mpl_module.\u001b[91m__class__\u001b[0m.\u001b[91m__name__\u001b[0m\u001b[33m}\u001b[0m\u001b[33m.\u001b[0m\u001b[33m{\u001b[0mhoo   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m140 \u001b[2m│   │   \u001b[0moutput = fn(*args, **kwargs)                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m141 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m142 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# restore current_fx when nested context\u001b[0m                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m143 \u001b[0m\u001b[2m│   \u001b[0mpl_module._current_fx_name = prev_fx_name                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mconfigure_optimizers\u001b[0m:\u001b[94m29\u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m26 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m loss                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m27 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m28 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mconfigure_optimizers\u001b[0m(\u001b[96mself\u001b[0m):                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m29 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m torch.optim.SGD(\u001b[96mself\u001b[0m.parameters(), lr = lr)                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m30 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m31 \u001b[0m\u001b[2m# train model\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m32 \u001b[0m\u001b[2m# initialize model\u001b[0m                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'lr'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Download Dataset\n",
    "training_ds = MNIST(root=\"data\",train=True,download=True,transform = T.ToTensor())\n",
    "validation_ds = MNIST(root=\"data\",train=False,download=True,transform = T.ToTensor())\n",
    "\n",
    "# Create DataLoader: it makes easy to iterate over batches\n",
    "train_dl = DataLoader(dataset=training_ds,batch_size=64, shuffle=True)\n",
    "valid_dl = DataLoader(dataset=validation_ds,batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "# Model Building\n",
    "class MNISTmodel(L.LightningModule):\n",
    "    def __init__(self, lr=0.5):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        # linear layer\n",
    "        self.Linear = torch.nn.Linear(in_features= 28 * 28, out_features=10)\n",
    "        \n",
    "    def forward(self, batched_x):\n",
    "        batched_x = batched_x.flatten(1,-1) # (bs,1,28,28) => (bs,784)\n",
    "        return self.Linear(batched_x)\n",
    "     \n",
    "    def training_step(self,batch,batch_idx):\n",
    "        xb,yb = batch\n",
    "        preds = model(xb)\n",
    "        loss = F.cross_entropy(input=preds, target=yb)\n",
    "        return loss\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.SGD(self.parameters(), lr = lr)\n",
    "    \n",
    "# train model\n",
    "# initialize model\n",
    "model = MNISTmodel()\n",
    "\n",
    "# initialize trainer\n",
    "trainer = L.Trainer(max_epochs=5)\n",
    "\n",
    "# train model\n",
    "trainer.fit(model, train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09265254",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21b24eb",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 176.987367,
   "end_time": "2023-08-24T11:22:30.436628",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-08-24T11:19:33.449261",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
